#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆ9ç§æ¨¡æ€ç»„åˆè®­ç»ƒè„šæœ¬
æ”¯æŒ (SMILES/Graph/Image) Ã— (SMILES/Graph/Image) = 9ç§ç»„åˆ
"""

import os
import sys
import argparse
import logging
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torch.utils.tensorboard import SummaryWriter
from torch.cuda.amp import autocast, GradScaler
import numpy as np
from tqdm import tqdm
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from scaffold_mol_gen.models.end2end_model import End2EndMolecularGenerator
from scaffold_mol_gen.models.graph_decoder import MolecularGraphDecoder as GraphDecoder
from scaffold_mol_gen.models.image_decoder import MolecularImageDecoder as ImageDecoder
from scaffold_mol_gen.data.multimodal_dataset import MultiModalMolecularDataset
from scaffold_mol_gen.training.metrics import GenerationMetrics
from scaffold_mol_gen.utils.mol_utils import MolecularUtils
from scaffold_mol_gen.data.multimodal_preprocessor import MultiModalPreprocessor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class NineModalityTrainer:
    """9ç§æ¨¡æ€ç»„åˆè®­ç»ƒå™¨"""
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        logger.info("åˆå§‹åŒ–9æ¨¡æ€è®­ç»ƒå™¨...")
        
        # åˆ›å»ºæ¨¡å‹
        logger.info("åˆ›å»ºç«¯åˆ°ç«¯æ¨¡å‹...")
        self.model = End2EndMolecularGenerator(
            hidden_size=768,
            molt5_path="/root/autodl-tmp/text2Mol-models/molt5-base",
            use_scibert=False,
            freeze_encoders=True,
            freeze_molt5=True,
            fusion_type='both',
            device=self.device
        )
        
        # åˆ›å»ºGraphå’ŒImageè§£ç å™¨
        logger.info("åˆ›å»ºGraphå’ŒImageè§£ç å™¨...")
        self.graph_decoder = GraphDecoder(input_dim=768).to(self.device)
        self.image_decoder = ImageDecoder(input_dim=768).to(self.device)
        
        # æŸå¤±æƒé‡
        self.loss_weights = {
            'smiles': args.smiles_weight,
            'graph': args.graph_weight,
            'image': args.image_weight
        }
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        logger.info("åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        self.train_loader, self.val_loader = self.create_data_loaders()
        
        # ä¼˜åŒ–å™¨
        all_params = (
            list(self.model.parameters()) + 
            list(self.graph_decoder.parameters()) + 
            list(self.image_decoder.parameters())
        )
        trainable_params = [p for p in all_params if p.requires_grad]
        
        self.optimizer = torch.optim.AdamW(
            trainable_params,
            lr=args.lr,
            weight_decay=1e-5
        )
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.scaler = GradScaler() if args.mixed_precision else None
        
        # è¾“å‡ºç›®å½•
        self.output_dir = Path(args.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # TensorBoard
        self.writer = SummaryWriter(self.output_dir / 'tensorboard')
        
        # ä¿å­˜é…ç½®
        with open(self.output_dir / 'config.json', 'w') as f:
            json.dump(vars(args), f, indent=2)
        
        logger.info(f"è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  è®¾å¤‡: {self.device}")
        logger.info(f"  å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in trainable_params):,}")
        logger.info(f"  è®­ç»ƒæ‰¹æ¬¡: {len(self.train_loader)}")
    
    def create_data_loaders(self):
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        # è®­ç»ƒé›†
        train_dataset = MultiModalMolecularDataset(
            csv_path=self.args.train_data,
            scaffold_modality='smiles',  # é»˜è®¤SMILESï¼Œä¼šåœ¨è®­ç»ƒä¸­è½¬æ¢
            filter_invalid=True
        )
        
        # é™åˆ¶æ ·æœ¬æ•°
        if self.args.sample_size > 0:
            train_dataset.data = train_dataset.data[:self.args.sample_size]
        
        # éªŒè¯é›†
        val_dataset = MultiModalMolecularDataset(
            csv_path=self.args.val_data,
            scaffold_modality='smiles',
            filter_invalid=True
        )
        
        if self.args.sample_size > 0:
            val_dataset.data = val_dataset.data[:min(1000, self.args.sample_size//5)]
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.args.batch_size,
            shuffle=True,
            num_workers=self.args.num_workers,
            pin_memory=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.args.batch_size,
            shuffle=False,
            num_workers=2
        )
        
        return train_loader, val_loader
    
    def prepare_multimodal_batch(self, batch):
        """å‡†å¤‡å¤šæ¨¡æ€æ‰¹æ¬¡æ•°æ®"""
        # è·å–åŸå§‹æ•°æ® - ä¿®æ­£é”®å
        scaffold_smiles = batch.get('scaffold_data')  # æ­£ç¡®çš„é”®å
        text = batch.get('text_data')  # æ­£ç¡®çš„é”®å
        target_smiles = batch.get('target_smiles')  # è¿™ä¸ªé”®åæ˜¯å¯¹çš„
        
        # åˆ›å»ºå¤šæ¨¡æ€æ•°æ®
        preprocessor = MultiModalPreprocessor()
        
        batch_data = {
            'text': text,
            'target_smiles': target_smiles
        }
        
        # å‡†å¤‡ä¸‰ç§scaffoldæ¨¡æ€
        if scaffold_smiles is not None:
            # SMILESæ¨¡æ€
            batch_data['scaffold_smiles'] = scaffold_smiles
            
            # Graphæ¨¡æ€ - ä»SMILESè½¬æ¢
            try:
                graphs = []
                for smiles in scaffold_smiles:
                    graph = preprocessor.smiles_to_graph(smiles)
                    if graph is not None:
                        graphs.append(graph)
                if graphs:
                    from torch_geometric.data import Batch
                    batch_data['scaffold_graph'] = Batch.from_data_list(graphs)
            except Exception as e:
                logger.debug(f"Graphè½¬æ¢å¤±è´¥: {e}")
            
            # Imageæ¨¡æ€ - ä»SMILESè½¬æ¢
            try:
                images = []
                for smiles in scaffold_smiles:
                    img = preprocessor.smiles_to_image(smiles)
                    if img is not None:
                        images.append(img)
                if images:
                    batch_data['scaffold_image'] = torch.stack([
                        torch.from_numpy(img).float() for img in images
                    ]).to(self.device)
            except Exception as e:
                logger.debug(f"Imageè½¬æ¢å¤±è´¥: {e}")
        
        # å‡†å¤‡ç›®æ ‡æ¨¡æ€ï¼ˆç”¨äºGraphå’ŒImageè§£ç å™¨ï¼‰
        if target_smiles is not None:
            # Target Graph
            try:
                target_graphs = []
                for smiles in target_smiles:
                    graph = preprocessor.smiles_to_graph(smiles)
                    if graph is not None:
                        target_graphs.append(graph)
                if target_graphs:
                    from torch_geometric.data import Batch
                    batch_data['target_graph'] = Batch.from_data_list(target_graphs)
            except:
                pass
            
            # Target Image
            try:
                target_images = []
                for smiles in target_smiles:
                    img = preprocessor.smiles_to_image(smiles)
                    if img is not None:
                        target_images.append(img)
                if target_images:
                    batch_data['target_image'] = torch.stack([
                        torch.from_numpy(img).float() for img in target_images
                    ]).to(self.device)
            except:
                pass
        
        return batch_data
    
    def compute_loss_for_combination(self, scaffold_data, text_data, target_data, 
                                    scaffold_modality, output_modality):
        """è®¡ç®—å•ä¸ªæ¨¡æ€ç»„åˆçš„æŸå¤±"""
        try:
            # è·å–èåˆç‰¹å¾
            output = self.model.forward(
                scaffold_data=scaffold_data,
                text_data=text_data,
                scaffold_modality=scaffold_modality,
                output_modality='smiles',  # å…ˆç”ŸæˆSMILES
                target_smiles=target_data.get('target_smiles') if output_modality == 'smiles' else None
            )
            
            # è°ƒè¯•ä¿¡æ¯
            if not output:
                logger.debug(f"{scaffold_modality}->{output_modality}: output is None")
                return None
                
            if output_modality == 'smiles':
                # SMILESæŸå¤±ç›´æ¥ä»modelè·å¾—
                if 'loss' in output and output['loss'] is not None:
                    loss_value = output['loss']
                    # ç¡®ä¿lossæ˜¯tensorå¹¶ä¸”æœ‰æ•ˆ
                    if torch.is_tensor(loss_value) and not torch.isnan(loss_value) and not torch.isinf(loss_value):
                        return loss_value
                    else:
                        logger.debug(f"{scaffold_modality}->smiles: æ— æ•ˆæŸå¤± {loss_value}")
                else:
                    logger.debug(f"{scaffold_modality}->smiles: æ— losså­—æ®µæˆ–lossä¸ºNone")
            
            elif output_modality == 'graph' and 'fused_features' in output:
                # GraphæŸå¤±
                if 'target_graph' in target_data:
                    graph_loss = self.graph_decoder.compute_loss(
                        output['fused_features'],
                        target_data['target_graph']
                    )
                    if graph_loss is not None and torch.is_tensor(graph_loss):
                        return graph_loss
                    else:
                        logger.debug(f"{scaffold_modality}->graph: GraphæŸå¤±è®¡ç®—å¤±è´¥")
                else:
                    logger.debug(f"{scaffold_modality}->graph: æ— target_graph")
            
            elif output_modality == 'image' and 'fused_features' in output:
                # ImageæŸå¤±
                if 'target_image' in target_data:
                    image_loss = self.image_decoder.compute_loss(
                        output['fused_features'],
                        target_data['target_image']
                    )
                    if image_loss is not None and torch.is_tensor(image_loss):
                        return image_loss
                    else:
                        logger.debug(f"{scaffold_modality}->image: ImageæŸå¤±è®¡ç®—å¤±è´¥")
                else:
                    logger.debug(f"{scaffold_modality}->image: æ— target_image")
        
        except Exception as e:
            logger.debug(f"æŸå¤±è®¡ç®—å¼‚å¸¸ {scaffold_modality}->{output_modality}: {str(e)}")
            import traceback
            logger.debug(traceback.format_exc())
        
        return None
    
    def compute_multi_task_loss(self, batch):
        """è®¡ç®—9ç§æ¨¡æ€ç»„åˆçš„å¤šä»»åŠ¡æŸå¤±"""
        losses = {}
        total_loss = None
        
        # 9ç§ç»„åˆ
        combinations = [
            ('smiles', 'smiles'), ('smiles', 'graph'), ('smiles', 'image'),
            ('graph', 'smiles'), ('graph', 'graph'), ('graph', 'image'),
            ('image', 'smiles'), ('image', 'graph'), ('image', 'image')
        ]
        
        for scaffold_mod, output_mod in combinations:
            scaffold_key = f'scaffold_{scaffold_mod}'
            
            if scaffold_key not in batch:
                continue
            
            scaffold_data = batch[scaffold_key]
            if scaffold_data is None:
                continue
            
            # è®¡ç®—æŸå¤±
            loss = self.compute_loss_for_combination(
                scaffold_data=scaffold_data,
                text_data=batch['text'],
                target_data=batch,
                scaffold_modality=scaffold_mod,
                output_modality=output_mod
            )
            
            if loss is not None and torch.is_tensor(loss):
                # åº”ç”¨æƒé‡
                weight = self.loss_weights.get(output_mod, 1.0)
                weighted_loss = loss * weight
                
                losses[f'{scaffold_mod}_to_{output_mod}'] = loss.item()
                
                # ç´¯åŠ åˆ°æ€»æŸå¤±
                if total_loss is None:
                    total_loss = weighted_loss
                else:
                    total_loss = total_loss + weighted_loss
        
        # ç¡®ä¿è¿”å›æœ‰æ•ˆçš„tensor
        if total_loss is None:
            # å¦‚æœæ‰€æœ‰æŸå¤±éƒ½å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªå°çš„å¸¸æ•°æŸå¤±
            total_loss = torch.tensor(0.01, device=self.device, requires_grad=True)
            logger.warning("æ‰€æœ‰æ¨¡æ€ç»„åˆæŸå¤±è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æŸå¤±")
        
        losses['total'] = total_loss
        return losses
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        self.graph_decoder.train()
        self.image_decoder.train()
        
        total_loss = 0
        loss_counts = {}
        
        progress_bar = tqdm(self.train_loader, desc=f'Epoch {epoch+1}/{self.args.epochs}')
        
        for batch_idx, raw_batch in enumerate(progress_bar):
            # å‡†å¤‡å¤šæ¨¡æ€æ‰¹æ¬¡
            batch = self.prepare_multimodal_batch(raw_batch)
            
            # è®¡ç®—æŸå¤±
            if self.scaler:
                with autocast():
                    losses = self.compute_multi_task_loss(batch)
                    loss = losses['total']
                
                # æ£€æŸ¥lossæ˜¯å¦æœ‰æ•ˆ
                if torch.is_tensor(loss) and loss.requires_grad:
                    # åå‘ä¼ æ’­
                    self.optimizer.zero_grad()
                    self.scaler.scale(loss).backward()
                    
                    # æ¢¯åº¦ç´¯ç§¯
                    if (batch_idx + 1) % self.args.gradient_accumulation == 0:
                        # åªæœ‰åœ¨æœ‰æ¢¯åº¦æ—¶æ‰æ›´æ–°
                        self.scaler.unscale_(self.optimizer)
                        torch.nn.utils.clip_grad_norm_(
                            [p for p in self.model.parameters() if p.requires_grad] +
                            list(self.graph_decoder.parameters()) +
                            list(self.image_decoder.parameters()),
                            self.args.max_grad_norm
                        )
                        self.scaler.step(self.optimizer)
                        self.scaler.update()
                    
                    total_loss += loss.item()
                else:
                    # å¦‚æœlossæ— æ•ˆï¼Œè·³è¿‡è¿™ä¸ªbatch
                    logger.warning(f"Batch {batch_idx}: è·³è¿‡æ— æ•ˆæŸå¤±")
                    continue
                    
                    # è®°å½•å„æ¨¡æ€æŸå¤±
                    for key, value in losses.items():
                        if key != 'total' and isinstance(value, (int, float)):
                            if key not in loss_counts:
                                loss_counts[key] = []
                            loss_counts[key].append(value)
            else:
                losses = self.compute_multi_task_loss(batch)
                loss = losses['total']
                
                if torch.is_tensor(loss) and loss.requires_grad:
                    loss.backward()
                    
                    if (batch_idx + 1) % self.args.gradient_accumulation == 0:
                        torch.nn.utils.clip_grad_norm_(
                            [p for p in self.model.parameters() if p.requires_grad] +
                            list(self.graph_decoder.parameters()) +
                            list(self.image_decoder.parameters()),
                            self.args.max_grad_norm
                        )
                        self.optimizer.step()
                        self.optimizer.zero_grad()
                    
                    total_loss += loss.item()
            
            # æ›´æ–°è¿›åº¦æ¡
            avg_loss = total_loss / (batch_idx + 1)
            progress_bar.set_postfix({'loss': f'{avg_loss:.4f}'})
            
            # å®šæœŸè®°å½•
            if batch_idx % 100 == 0 and batch_idx > 0:
                logger.info(f"Batch {batch_idx}, Avg Loss: {avg_loss:.4f}")
                
                # è®°å½•å„æ¨¡æ€å¹³å‡æŸå¤±
                for key, values in loss_counts.items():
                    if values:
                        avg = sum(values) / len(values)
                        logger.info(f"  {key}: {avg:.4f}")
        
        return total_loss / len(self.train_loader)
    
    def validate(self):
        """éªŒè¯"""
        self.model.eval()
        self.graph_decoder.eval()
        self.image_decoder.eval()
        
        total_loss = 0
        
        with torch.no_grad():
            for raw_batch in tqdm(self.val_loader, desc='Validation'):
                batch = self.prepare_multimodal_batch(raw_batch)
                losses = self.compute_multi_task_loss(batch)
                
                if 'total' in losses and torch.is_tensor(losses['total']):
                    total_loss += losses['total'].item()
        
        return total_loss / len(self.val_loader)
    
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        logger.info("=" * 60)
        logger.info("ğŸš€ å¼€å§‹9ç§æ¨¡æ€ç»„åˆè®­ç»ƒ")
        logger.info(f"è®¾å¤‡: {self.device}")
        logger.info(f"æ‰¹å¤§å°: {self.args.batch_size}")
        logger.info(f"æ¢¯åº¦ç´¯ç§¯: {self.args.gradient_accumulation}")
        logger.info(f"æœ‰æ•ˆæ‰¹å¤§å°: {self.args.batch_size * self.args.gradient_accumulation}")
        logger.info(f"æ··åˆç²¾åº¦: {self.args.mixed_precision}")
        logger.info("=" * 60)
        
        best_val_loss = float('inf')
        
        for epoch in range(self.args.epochs):
            start_time = time.time()
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(epoch)
            
            # éªŒè¯
            val_loss = self.validate()
            
            epoch_time = time.time() - start_time
            
            logger.info(f"Epoch {epoch+1}/{self.args.epochs}: "
                       f"Train Loss: {train_loss:.4f}, "
                       f"Val Loss: {val_loss:.4f}, "
                       f"Time: {epoch_time:.1f}s")
            
            # TensorBoardè®°å½•
            self.writer.add_scalar('Loss/Train', train_loss, epoch)
            self.writer.add_scalar('Loss/Val', val_loss, epoch)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                self.save_checkpoint(epoch, val_loss, is_best=True)
                logger.info(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯æŸå¤±: {val_loss:.4f}")
            
            # å®šæœŸä¿å­˜
            if (epoch + 1) % self.args.save_interval == 0:
                self.save_checkpoint(epoch, val_loss, is_best=False)
        
        logger.info("ğŸ‰ è®­ç»ƒå®Œæˆ!")
        return {'best_val_loss': best_val_loss}
    
    def save_checkpoint(self, epoch, val_loss, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'graph_decoder_state_dict': self.graph_decoder.state_dict(),
            'image_decoder_state_dict': self.image_decoder.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'val_loss': val_loss,
        }
        
        if self.scaler:
            checkpoint['scaler_state_dict'] = self.scaler.state_dict()
        
        if is_best:
            path = self.output_dir / 'best_model.pth'
        else:
            path = self.output_dir / f'checkpoint_epoch_{epoch+1}.pth'
        
        torch.save(checkpoint, path)
        logger.info(f"ä¿å­˜æ£€æŸ¥ç‚¹: {path}")


def main():
    parser = argparse.ArgumentParser(description='9ç§æ¨¡æ€ç»„åˆè®­ç»ƒ')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--train-data', default='Datasets/train.csv',
                        help='è®­ç»ƒæ•°æ®è·¯å¾„')
    parser.add_argument('--val-data', default='Datasets/validation.csv',
                        help='éªŒè¯æ•°æ®è·¯å¾„')
    parser.add_argument('--sample-size', type=int, default=0,
                        help='æ ·æœ¬æ•°é‡é™åˆ¶ï¼ˆ0=å…¨éƒ¨ï¼‰')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch-size', type=int, default=8,
                        help='æ‰¹å¤§å°')
    parser.add_argument('--gradient-accumulation', type=int, default=1,
                        help='æ¢¯åº¦ç´¯ç§¯æ­¥æ•°')
    parser.add_argument('--epochs', type=int, default=5,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=5e-5,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--max-grad-norm', type=float, default=1.0,
                        help='æ¢¯åº¦è£å‰ª')
    parser.add_argument('--mixed-precision', action='store_true',
                        help='å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ')
    parser.add_argument('--num-workers', type=int, default=4,
                        help='æ•°æ®åŠ è½½è¿›ç¨‹æ•°')
    
    # æŸå¤±æƒé‡
    parser.add_argument('--smiles-weight', type=float, default=1.0,
                        help='SMILESæŸå¤±æƒé‡')
    parser.add_argument('--graph-weight', type=float, default=0.7,
                        help='GraphæŸå¤±æƒé‡')
    parser.add_argument('--image-weight', type=float, default=0.5,
                        help='ImageæŸå¤±æƒé‡')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output-dir', 
                        default='/root/autodl-tmp/text2Mol-outputs/nine_modal_training',
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--save-interval', type=int, default=1,
                        help='ä¿å­˜é—´éš”')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = NineModalityTrainer(args)
    
    # å¼€å§‹è®­ç»ƒ
    stats = trainer.train()
    
    logger.info(f"æœ€ç»ˆç»“æœ: {stats}")


if __name__ == "__main__":
    main()