# ğŸš€ å¿«é€Ÿå¼€å§‹åå°è®­ç»ƒå’Œç›‘æ§

## ä¸€ã€æœ€ç®€å•çš„æ–¹æ³• - ä½¿ç”¨ä¸€é”®å¯åŠ¨è„šæœ¬

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /root/text2Mol/scaffold-mol-generation

# è¿è¡Œåå°è®­ç»ƒå¯åŠ¨å™¨
./start_background_training.sh
```

å¯åŠ¨åé€‰æ‹©è®­ç»ƒæ¨¡å¼ï¼š
- **1** - å¿«é€Ÿæµ‹è¯•ï¼ˆ10åˆ†é’Ÿï¼ŒéªŒè¯ç³»ç»Ÿï¼‰
- **2** - æ ‡å‡†è®­ç»ƒï¼ˆ2å°æ—¶ï¼ŒåŸºç¡€æ¨¡å‹ï¼‰
- **3** - å®Œæ•´è®­ç»ƒï¼ˆ8å°æ—¶ï¼Œç”Ÿäº§æ¨¡å‹ï¼‰
- **4** - é«˜æ€§èƒ½è®­ç»ƒï¼ˆå¤§æ‰¹æ¬¡ï¼Œæœ€ä½³æ•ˆæœï¼‰

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- âœ… å¯åŠ¨åå°è®­ç»ƒè¿›ç¨‹
- âœ… åˆ›å»ºç›‘æ§ç³»ç»Ÿ
- âœ… ç”Ÿæˆç®¡ç†è„šæœ¬
- âœ… è®¾ç½®æ—¥å¿—è®°å½•

---

## äºŒã€æ‰‹åŠ¨å¯åŠ¨åå°è®­ç»ƒ

### 1. å¿«é€Ÿæµ‹è¯•è®­ç»ƒï¼ˆéªŒè¯ç³»ç»Ÿå·¥ä½œï¼‰

```bash
# 100ä¸ªæ ·æœ¬ï¼Œ2è½®è®­ç»ƒï¼Œçº¦10åˆ†é’Ÿ
nohup python train_9_modalities.py \
    --train-data Datasets/train.csv \
    --val-data Datasets/validation.csv \
    --batch-size 8 \
    --epochs 2 \
    --sample-size 100 \
    --output-dir /root/autodl-tmp/text2Mol-outputs/test_$(date +%Y%m%d_%H%M%S) \
    > training.log 2>&1 &

# è®°å½•PID
echo $! > train.pid
```

### 2. æ ‡å‡†è®­ç»ƒï¼ˆæ¨èï¼‰

```bash
# 5000ä¸ªæ ·æœ¬ï¼Œ5è½®è®­ç»ƒï¼Œçº¦2å°æ—¶
nohup python train_9_modalities.py \
    --train-data Datasets/train.csv \
    --val-data Datasets/validation.csv \
    --batch-size 16 \
    --gradient-accumulation 2 \
    --epochs 5 \
    --sample-size 5000 \
    --lr 5e-5 \
    --mixed-precision \
    --output-dir /root/autodl-tmp/text2Mol-outputs/standard_$(date +%Y%m%d_%H%M%S) \
    > training.log 2>&1 &
```

### 3. å®Œæ•´è®­ç»ƒï¼ˆç”Ÿäº§çº§ï¼‰

```bash
# å…¨éƒ¨æ•°æ®ï¼Œ10è½®è®­ç»ƒï¼Œçº¦8å°æ—¶
nohup python train_9_modalities.py \
    --train-data Datasets/train.csv \
    --val-data Datasets/validation.csv \
    --batch-size 16 \
    --gradient-accumulation 3 \
    --epochs 10 \
    --lr 5e-5 \
    --mixed-precision \
    --num-workers 4 \
    --output-dir /root/autodl-tmp/text2Mol-outputs/full_$(date +%Y%m%d_%H%M%S) \
    --save-steps 500 \
    --smiles-weight 1.0 \
    --graph-weight 0.7 \
    --image-weight 0.5 \
    > training.log 2>&1 &
```

---

## ä¸‰ã€ç›‘æ§è®­ç»ƒè¿›åº¦

### æ–¹æ³•1ï¼šå®æ—¶ç›‘æ§ä»ªè¡¨æ¿ï¼ˆæ¨èï¼‰

```bash
# å¯åŠ¨å®æ—¶ç›‘æ§ï¼ˆæ¯10ç§’æ›´æ–°ï¼‰
python real_time_monitor.py --output-dir /root/autodl-tmp/text2Mol-outputs/ä½ çš„è®­ç»ƒç›®å½• --interval 10
```

æ˜¾ç¤ºå†…å®¹ï¼š
- ğŸ”¥ GPUä½¿ç”¨ç‡ã€æ¸©åº¦ã€å†…å­˜
- ğŸ’» CPUã€RAMã€ç£ç›˜ä½¿ç”¨
- ğŸ“ˆ è®­ç»ƒæŸå¤±ã€éªŒè¯æŸå¤±
- âš ï¸ ç³»ç»Ÿå‘Šè­¦

### æ–¹æ³•2ï¼šæŸ¥çœ‹è®­ç»ƒæ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f training.log

# åªçœ‹æŸå¤±ä¿¡æ¯
tail -f training.log | grep -E "Loss|Epoch"

# æŸ¥çœ‹éªŒè¯ç»“æœ
tail -f training.log | grep "Validation"
```

### æ–¹æ³•3ï¼šç›‘æ§GPUä½¿ç”¨

```bash
# å®æ—¶GPUç›‘æ§
watch -n 5 nvidia-smi

# æˆ–è€…æ›´è¯¦ç»†çš„ä¿¡æ¯
nvidia-smi -l 5
```

### æ–¹æ³•4ï¼šTensorBoardå¯è§†åŒ–

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir /root/autodl-tmp/text2Mol-outputs/ä½ çš„è®­ç»ƒç›®å½•/tensorboard --port 6006

# ç„¶ååœ¨æµè§ˆå™¨è®¿é—® http://localhost:6006
```

---

## å››ã€ç®¡ç†è®­ç»ƒè¿›ç¨‹

### æŸ¥çœ‹è®­ç»ƒçŠ¶æ€

```bash
# å¦‚æœä½¿ç”¨äº†å¯åŠ¨è„šæœ¬ï¼Œç›´æ¥è¿è¡Œ
/root/autodl-tmp/text2Mol-outputs/ä½ çš„è®­ç»ƒç›®å½•/check_status.sh

# æˆ–æ‰‹åŠ¨æŸ¥çœ‹è¿›ç¨‹
ps aux | grep train_9_modalities
```

### åœæ­¢è®­ç»ƒ

```bash
# å¦‚æœä½¿ç”¨äº†å¯åŠ¨è„šæœ¬
/root/autodl-tmp/text2Mol-outputs/ä½ çš„è®­ç»ƒç›®å½•/stop_training.sh

# æˆ–æ‰‹åŠ¨åœæ­¢
kill $(cat train.pid)
```

### æ¢å¤è®­ç»ƒï¼ˆä»æ£€æŸ¥ç‚¹ï¼‰

```bash
python train_9_modalities.py \
    --resume-from /root/autodl-tmp/text2Mol-outputs/ä½ çš„è®­ç»ƒç›®å½•/checkpoints/æœ€æ–°æ£€æŸ¥ç‚¹.pth \
    [å…¶ä»–åŸå§‹å‚æ•°...]
```

---

## äº”ã€å¸¸è§é—®é¢˜

### 1. CUDAå†…å­˜ä¸è¶³

å‡å°æ‰¹å¤§å°æˆ–å¢åŠ æ¢¯åº¦ç´¯ç§¯ï¼š
```bash
--batch-size 8 --gradient-accumulation 4  # æœ‰æ•ˆæ‰¹å¤§å°32
```

### 2. è®­ç»ƒå¤ªæ…¢

- å¯ç”¨æ··åˆç²¾åº¦ï¼š`--mixed-precision`
- å¢åŠ æ•°æ®åŠ è½½è¿›ç¨‹ï¼š`--num-workers 8`
- å‡å°‘éªŒè¯é¢‘ç‡ï¼š`--val-interval 1000`

### 3. æŸ¥çœ‹è®­ç»ƒæ˜¯å¦æ­£å¸¸

```bash
# æ£€æŸ¥æœ€æ–°çš„è®­ç»ƒæ—¥å¿—
tail -n 50 training.log

# æ£€æŸ¥GPUæ˜¯å¦åœ¨ä½¿ç”¨
nvidia-smi

# æ£€æŸ¥è¾“å‡ºç›®å½•å¤§å°
du -sh /root/autodl-tmp/text2Mol-outputs/ä½ çš„è®­ç»ƒç›®å½•
```

---

## å…­ã€æ¨èé…ç½®

### å¿«é€ŸéªŒè¯ï¼ˆ10åˆ†é’Ÿï¼‰
```bash
./start_background_training.sh
# é€‰æ‹© 1
```

### æ—¥å¸¸å¼€å‘ï¼ˆ2å°æ—¶ï¼‰
```bash
./start_background_training.sh
# é€‰æ‹© 2
```

### ç”Ÿäº§è®­ç»ƒï¼ˆ8å°æ—¶ï¼‰
```bash
./start_background_training.sh
# é€‰æ‹© 3
```

---

## ğŸ¯ ç°åœ¨å°±å¼€å§‹ï¼

æœ€ç®€å•çš„å¼€å§‹æ–¹å¼ï¼š
```bash
cd /root/text2Mol/scaffold-mol-generation
./start_background_training.sh
# é€‰æ‹© 1 è¿›è¡Œå¿«é€Ÿæµ‹è¯•
```

è®­ç»ƒä¼šåœ¨åå°è¿è¡Œï¼Œä½ å¯ä»¥ï¼š
- å…³é—­ç»ˆç«¯ï¼Œè®­ç»ƒç»§ç»­
- éšæ—¶æŸ¥çœ‹è¿›åº¦
- å®æ—¶ç›‘æ§æ€§èƒ½
- å®‰å…¨åœæ­¢/æ¢å¤