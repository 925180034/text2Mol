#!/usr/bin/env python3
"""
å®Œæ•´çš„å¤šæ¨¡æ€åˆ†å­ç”Ÿæˆç³»ç»Ÿæµ‹è¯•
æµ‹è¯•æ‰€æœ‰9ç§è¾“å…¥è¾“å‡ºç»„åˆ
"""

import os
import sys
import torch
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json
from tqdm import tqdm
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent))

import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥å¿…è¦çš„ç»„ä»¶
from scaffold_mol_gen.models.end2end_model import End2EndMolecularGenerator
from scaffold_mol_gen.data.multimodal_preprocessor import MultiModalPreprocessor
# ç®€åŒ–çš„è¯„ä¼°æŒ‡æ ‡
def calculate_validity(smiles_list):
    from rdkit import Chem
    valid = sum(1 for s in smiles_list if Chem.MolFromSmiles(s) is not None)
    return valid / len(smiles_list) if smiles_list else 0

def calculate_uniqueness(smiles_list):
    unique = len(set(smiles_list))
    return unique / len(smiles_list) if smiles_list else 0

def calculate_novelty(generated, reference):
    novel = sum(1 for s in generated if s not in reference)
    return novel / len(generated) if generated else 0
import torchvision.transforms as transforms
from torch_geometric.data import Batch

class MultiModalEvaluator:
    """å¤šæ¨¡æ€è¯„ä¼°å™¨"""
    
    def __init__(self, model_path: str = None, device: str = 'cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ¨¡åž‹
        if model_path and Path(model_path).exists():
            logger.info(f"åŠ è½½æ¨¡åž‹: {model_path}")
            checkpoint = torch.load(model_path, map_location=self.device)
            self.model = checkpoint.get('model', End2EndMolecularGenerator())
            self.model.to(self.device)
            self.model.eval()
        else:
            logger.info("åˆ›å»ºæ–°æ¨¡åž‹å®žä¾‹")
            self.model = End2EndMolecularGenerator(device=str(self.device))
            self.model.to(self.device)
            self.model.eval()
        
        # åˆå§‹åŒ–é¢„å¤„ç†å™¨
        self.preprocessor = MultiModalPreprocessor()
        
        # å®šä¹‰æ‰€æœ‰9ç§ç»„åˆ
        self.combinations = [
            ('smiles', 'smiles', 'âœ…'),
            ('smiles', 'graph', 'âœ…'),
            ('smiles', 'image', 'âœ…'),
            ('graph', 'smiles', 'âœ…'),
            ('graph', 'graph', 'âœ…'),
            ('graph', 'image', 'âœ…'),
            ('image', 'smiles', 'âœ…'),
            ('image', 'graph', 'âœ…'),
            ('image', 'image', 'âœ…'),
        ]
        
        # å›¾åƒè½¬æ¢
        self.image_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                              std=[0.229, 0.224, 0.225])
        ])
    
    def prepare_scaffold_data(self, smiles_list: List[str], modality: str) -> Any:
        """å‡†å¤‡ä¸åŒæ¨¡æ€çš„scaffoldæ•°æ®"""
        
        if modality == 'smiles':
            return smiles_list
        
        elif modality == 'graph':
            graphs = []
            for smiles in smiles_list:
                graph = self.preprocessor.smiles_to_graph(smiles)
                if graph is not None:
                    graphs.append(graph)
                else:
                    # åˆ›å»ºä¸€ä¸ªç®€å•çš„é»˜è®¤å›¾
                    logger.warning(f"æ— æ³•è½¬æ¢SMILESåˆ°å›¾: {smiles}")
                    # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ç¢³åŽŸå­ä½œä¸ºé»˜è®¤
                    import torch
                    from torch_geometric.data import Data
                    x = torch.tensor([[6, 0, 0, 0, 0, 0, 0, 0, 0, 12.01]], dtype=torch.float)
                    edge_index = torch.tensor([[0], [0]], dtype=torch.long)
                    edge_attr = torch.tensor([[1, 0, 0, 0, 0]], dtype=torch.float)
                    graphs.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr))
            
            # æ‰¹å¤„ç†å›¾æ•°æ®
            if graphs:
                return Batch.from_data_list(graphs).to(self.device)
            return None
        
        elif modality == 'image':
            images = []
            for smiles in smiles_list:
                image = self.preprocessor.smiles_to_image(smiles)
                if image is not None:
                    if isinstance(image, np.ndarray):
                        # è½¬æ¢ä¸ºtensor
                        image_tensor = self.image_transform(image)
                        images.append(image_tensor)
                else:
                    # åˆ›å»ºé»˜è®¤çš„ç™½è‰²å›¾åƒ
                    logger.warning(f"æ— æ³•è½¬æ¢SMILESåˆ°å›¾åƒ: {smiles}")
                    default_img = np.ones((224, 224, 3), dtype=np.uint8) * 255
                    image_tensor = self.image_transform(default_img)
                    images.append(image_tensor)
            
            # æ‰¹å¤„ç†å›¾åƒ
            if images:
                return torch.stack(images).to(self.device)
            return None
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡æ€: {modality}")
    
    def test_single_combination(self, 
                               scaffold_modality: str,
                               output_modality: str,
                               test_smiles: List[str],
                               test_texts: List[str]) -> Dict:
        """æµ‹è¯•å•ä¸ªè¾“å…¥è¾“å‡ºç»„åˆ"""
        
        logger.info(f"\næµ‹è¯•ç»„åˆ: {scaffold_modality} â†’ {output_modality}")
        result = {
            'scaffold_modality': scaffold_modality,
            'output_modality': output_modality,
            'status': 'testing',
            'metrics': {},
            'examples': [],
            'error': None
        }
        
        try:
            # å‡†å¤‡è¾“å…¥æ•°æ®
            scaffold_data = self.prepare_scaffold_data(test_smiles, scaffold_modality)
            if scaffold_data is None:
                raise ValueError(f"æ— æ³•å‡†å¤‡{scaffold_modality}æ¨¡æ€æ•°æ®")
            
            # ç”Ÿæˆè¾“å‡º
            with torch.no_grad():
                if output_modality == 'smiles':
                    # ç›´æŽ¥ç”ŸæˆSMILES
                    generated = self.model.generate(
                        scaffold_data=scaffold_data,
                        text_data=test_texts,
                        scaffold_modality=scaffold_modality,
                        output_modality='smiles',
                        num_beams=3,
                        temperature=0.8,
                        max_length=128
                    )
                elif output_modality in ['graph', 'image']:
                    # å…ˆç”ŸæˆSMILESï¼Œå†è½¬æ¢
                    smiles_output = self.model.generate(
                        scaffold_data=scaffold_data,
                        text_data=test_texts,
                        scaffold_modality=scaffold_modality,
                        output_modality='smiles',
                        num_beams=3,
                        temperature=0.8,
                        max_length=128
                    )
                    
                    # è½¬æ¢åˆ°ç›®æ ‡æ¨¡æ€
                    if output_modality == 'graph':
                        generated = []
                        for smi in smiles_output:
                            graph = self.preprocessor.smiles_to_graph(smi)
                            generated.append(graph)
                    else:  # image
                        generated = []
                        for smi in smiles_output:
                            image = self.preprocessor.smiles_to_image(smi)
                            generated.append(image)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ¨¡æ€: {output_modality}")
            
            # è®¡ç®—æŒ‡æ ‡ï¼ˆä»…å¯¹SMILESè¾“å‡ºï¼‰
            if output_modality == 'smiles' and isinstance(generated, list):
                result['metrics'] = {
                    'validity': calculate_validity(generated),
                    'uniqueness': calculate_uniqueness(generated),
                    'novelty': calculate_novelty(generated, test_smiles),
                    'samples_generated': len(generated)
                }
            elif output_modality == 'graph':
                valid_graphs = sum(1 for g in generated if g is not None)
                result['metrics'] = {
                    'valid_graphs': valid_graphs,
                    'total_graphs': len(generated),
                    'success_rate': valid_graphs / len(generated) if generated else 0
                }
            elif output_modality == 'image':
                valid_images = sum(1 for img in generated if img is not None)
                result['metrics'] = {
                    'valid_images': valid_images,
                    'total_images': len(generated),
                    'success_rate': valid_images / len(generated) if generated else 0
                }
            
            # ä¿å­˜ç¤ºä¾‹
            for i in range(min(3, len(test_smiles))):
                example = {
                    'input_smiles': test_smiles[i],
                    'input_text': test_texts[i][:100] + '...' if len(test_texts[i]) > 100 else test_texts[i],
                    'input_modality': scaffold_modality,
                    'output_modality': output_modality
                }
                
                if output_modality == 'smiles' and i < len(generated):
                    example['generated'] = generated[i] if isinstance(generated[i], str) else str(generated[i])
                elif output_modality == 'graph' and i < len(generated) and generated[i]:
                    example['generated'] = f"Graph(nodes={generated[i].x.shape[0]}, edges={generated[i].edge_index.shape[1]//2})"
                elif output_modality == 'image' and i < len(generated) and generated[i] is not None:
                    example['generated'] = f"Image(shape={generated[i].shape if hasattr(generated[i], 'shape') else 'unknown'})"
                
                result['examples'].append(example)
            
            result['status'] = 'success'
            logger.info(f"  âœ… æˆåŠŸ - {result['metrics']}")
            
        except Exception as e:
            result['status'] = 'failed'
            result['error'] = str(e)
            logger.error(f"  âŒ å¤±è´¥: {e}")
        
        return result
    
    def run_all_tests(self, test_data_path: str = None, sample_size: int = 10):
        """è¿è¡Œæ‰€æœ‰ç»„åˆæµ‹è¯•"""
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        if test_data_path and Path(test_data_path).exists():
            logger.info(f"åŠ è½½æµ‹è¯•æ•°æ®: {test_data_path}")
            test_df = pd.read_csv(test_data_path).head(sample_size)
            test_smiles = test_df['SMILES'].tolist() if 'SMILES' in test_df else test_df.iloc[:, 0].tolist()
            test_texts = test_df['description'].tolist() if 'description' in test_df else test_df.iloc[:, 1].tolist()
        else:
            logger.info("ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•")
            test_smiles = [
                "CCO",  # ä¹™é†‡
                "CC(=O)O",  # ä¹™é…¸
                "c1ccccc1",  # è‹¯
                "CC(C)CC(C)(C)O",  # å¤æ‚åˆ†å­
                "O=C(O)COc1ccc(Cl)c2cccnc12",  # æ›´å¤æ‚çš„åˆ†å­
            ]
            test_texts = [
                "A simple alcohol molecule",
                "An organic acid",
                "An aromatic ring",
                "A branched alcohol",
                "A complex heterocyclic compound"
            ] * (sample_size // 5 + 1)
            test_smiles = test_smiles * (sample_size // 5 + 1)
            test_smiles = test_smiles[:sample_size]
            test_texts = test_texts[:sample_size]
        
        logger.info(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_smiles)}")
        
        # æµ‹è¯•æ‰€æœ‰ç»„åˆ
        all_results = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'model_info': {
                'device': str(self.device),
                'sample_size': len(test_smiles)
            },
            'combinations': []
        }
        
        for scaffold_mod, output_mod, status_icon in self.combinations:
            logger.info(f"\n{'='*60}")
            logger.info(f"æµ‹è¯•ç»„åˆ {status_icon}: {scaffold_mod} â†’ {output_mod}")
            logger.info(f"{'='*60}")
            
            result = self.test_single_combination(
                scaffold_modality=scaffold_mod,
                output_modality=output_mod,
                test_smiles=test_smiles,
                test_texts=test_texts
            )
            
            all_results['combinations'].append(result)
        
        # ç»Ÿè®¡ç»“æžœ
        success_count = sum(1 for c in all_results['combinations'] if c['status'] == 'success')
        failed_count = sum(1 for c in all_results['combinations'] if c['status'] == 'failed')
        
        all_results['summary'] = {
            'total_combinations': len(self.combinations),
            'successful': success_count,
            'failed': failed_count,
            'success_rate': success_count / len(self.combinations) if self.combinations else 0
        }
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æµ‹è¯•æ‰€æœ‰å¤šæ¨¡æ€ç»„åˆ')
    parser.add_argument('--model-path', type=str, 
                      default='/root/autodl-tmp/text2Mol-outputs/optimized_20250809_105726/best_model.pt',
                      help='æ¨¡åž‹è·¯å¾„')
    parser.add_argument('--test-file', type=str,
                      default='Datasets/test.csv',
                      help='æµ‹è¯•æ•°æ®æ–‡ä»¶')
    parser.add_argument('--sample-size', type=int, default=10,
                      help='æµ‹è¯•æ ·æœ¬æ•°')
    parser.add_argument('--device', type=str, default='cuda',
                      help='è®¾å¤‡')
    parser.add_argument('--output-dir', type=str, default='.',
                      help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    logger.info("="*70)
    logger.info("ðŸ§ª å¤šæ¨¡æ€åˆ†å­ç”Ÿæˆç³»ç»Ÿå…¨é¢æµ‹è¯•")
    logger.info("="*70)
    logger.info(f"æµ‹è¯•æ‰€æœ‰9ç§è¾“å…¥è¾“å‡ºç»„åˆ")
    logger.info(f"æ¯ç§ç»„åˆæµ‹è¯•{args.sample_size}ä¸ªæ ·æœ¬")
    logger.info("="*70)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = MultiModalEvaluator(
        model_path=args.model_path,
        device=args.device
    )
    
    # è¿è¡Œæµ‹è¯•
    results = evaluator.run_all_tests(
        test_data_path=args.test_file,
        sample_size=args.sample_size
    )
    
    # ä¿å­˜ç»“æžœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = Path(args.output_dir) / f"multimodal_test_results_{timestamp}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    logger.info(f"\n{'='*70}")
    logger.info("ðŸ“Š æµ‹è¯•å®Œæˆ")
    logger.info(f"{'='*70}")
    logger.info(f"æ€»ç»„åˆæ•°: {results['summary']['total_combinations']}")
    logger.info(f"æˆåŠŸ: {results['summary']['successful']}")
    logger.info(f"å¤±è´¥: {results['summary']['failed']}")
    logger.info(f"æˆåŠŸçŽ‡: {results['summary']['success_rate']:.1%}")
    logger.info(f"\nç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
    
    # æ‰“å°è¯¦ç»†ç»“æžœ
    logger.info(f"\n{'='*70}")
    logger.info("ðŸ“‹ è¯¦ç»†ç»“æžœ")
    logger.info(f"{'='*70}")
    
    for combo in results['combinations']:
        status_icon = "âœ…" if combo['status'] == 'success' else "âŒ"
        logger.info(f"{status_icon} {combo['scaffold_modality']}â†’{combo['output_modality']}: {combo['status']}")
        if combo['metrics']:
            for key, value in combo['metrics'].items():
                if isinstance(value, float):
                    logger.info(f"    {key}: {value:.4f}")
                else:
                    logger.info(f"    {key}: {value}")
        if combo['error']:
            logger.info(f"    é”™è¯¯: {combo['error']}")

if __name__ == "__main__":
    main()