#!/usr/bin/env python3
"""
ä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹æµ‹è¯•
"""

import os
import sys
import torch
import pandas as pd
from pathlib import Path
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥ç»„ä»¶
from scaffold_mol_gen.models.end2end_model import End2EndMolecularGenerator
from fix_graph_input import FixedGraphProcessor
from fix_image_input import FixedImageProcessor

# è¯„ä¼°æŒ‡æ ‡
def calculate_validity(smiles_list):
    from rdkit import Chem
    valid = sum(1 for s in smiles_list if Chem.MolFromSmiles(s) is not None)
    return valid / len(smiles_list) if smiles_list else 0

def calculate_uniqueness(smiles_list):
    unique = len(set(smiles_list))
    return unique / len(smiles_list) if smiles_list else 0

def main():
    # ä½¿ç”¨æ‚¨è®­ç»ƒå¥½çš„æ¨¡å‹
    model_path = "/root/autodl-tmp/text2Mol-outputs/optimized_20250809_105726/best_model.pt"
    
    logger.info(f"åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹: {model_path}")
    
    # åŠ è½½æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    checkpoint = torch.load(model_path, map_location=device)
    
    # ä»checkpointæ¢å¤æ¨¡å‹
    if 'model_state_dict' in checkpoint:
        model = End2EndMolecularGenerator(device=str(device))
        model.load_state_dict(checkpoint['model_state_dict'])
    elif 'model' in checkpoint:
        model = checkpoint['model']
    else:
        logger.error("æ— æ³•ä»checkpointåŠ è½½æ¨¡å‹")
        return
    
    model.to(device)
    model.eval()
    
    logger.info(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {device}")
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_df = pd.read_csv("Datasets/test.csv").head(5)
    test_smiles = test_df['SMILES'].tolist()
    test_texts = test_df['description'].tolist() if 'description' in test_df else test_df['text'].tolist()
    
    logger.info(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_smiles)}")
    
    # ä½¿ç”¨ä¿®å¤çš„å¤„ç†å™¨
    graph_processor = FixedGraphProcessor
    image_processor = FixedImageProcessor(image_size=224)
    
    results = {}
    
    # æµ‹è¯•1: SMILES â†’ SMILES
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯• SMILES â†’ SMILES")
    logger.info("="*60)
    
    try:
        with torch.no_grad():
            generated = model.generate(
                scaffold_data=test_smiles,
                text_data=test_texts,
                scaffold_modality='smiles',
                output_modality='smiles',
                num_beams=5,
                temperature=0.8,
                max_length=128
            )
        
        validity = calculate_validity(generated)
        uniqueness = calculate_uniqueness(generated)
        
        logger.info(f"ç”Ÿæˆçš„SMILESç¤ºä¾‹:")
        for i, (input_s, gen_s) in enumerate(zip(test_smiles[:3], generated[:3])):
            logger.info(f"  è¾“å…¥: {input_s[:50]}...")
            logger.info(f"  ç”Ÿæˆ: {gen_s}")
        
        logger.info(f"æœ‰æ•ˆç‡: {validity:.2%}")
        logger.info(f"å”¯ä¸€æ€§: {uniqueness:.2%}")
        
        results['smiles_to_smiles'] = {
            'validity': validity,
            'uniqueness': uniqueness,
            'examples': generated[:3]
        }
        
    except Exception as e:
        logger.error(f"SMILESâ†’SMILESå¤±è´¥: {e}")
        results['smiles_to_smiles'] = {'error': str(e)}
    
    # æµ‹è¯•2: IMAGE â†’ SMILES
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯• IMAGE â†’ SMILES")
    logger.info("="*60)
    
    try:
        # å‡†å¤‡å›¾åƒæ‰¹æ¬¡
        image_batch = image_processor.prepare_image_batch(test_smiles, str(device))
        
        if image_batch is not None:
            with torch.no_grad():
                generated = model.generate(
                    scaffold_data=image_batch,
                    text_data=test_texts,
                    scaffold_modality='image',
                    output_modality='smiles',
                    num_beams=5,
                    temperature=0.8,
                    max_length=128
                )
            
            validity = calculate_validity(generated)
            uniqueness = calculate_uniqueness(generated)
            
            logger.info(f"ç”Ÿæˆçš„SMILESç¤ºä¾‹:")
            for i, gen_s in enumerate(generated[:3]):
                logger.info(f"  ç”Ÿæˆ{i+1}: {gen_s}")
            
            logger.info(f"æœ‰æ•ˆç‡: {validity:.2%}")
            logger.info(f"å”¯ä¸€æ€§: {uniqueness:.2%}")
            
            results['image_to_smiles'] = {
                'validity': validity,
                'uniqueness': uniqueness,
                'examples': generated[:3]
            }
        else:
            logger.error("æ— æ³•å‡†å¤‡å›¾åƒæ•°æ®")
            results['image_to_smiles'] = {'error': "Image preparation failed"}
            
    except Exception as e:
        logger.error(f"IMAGEâ†’SMILESå¤±è´¥: {e}")
        results['image_to_smiles'] = {'error': str(e)}
    
    # æµ‹è¯•3: GRAPH â†’ SMILES
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯• GRAPH â†’ SMILES")
    logger.info("="*60)
    
    try:
        # å‡†å¤‡å›¾æ‰¹æ¬¡ - ä½œä¸ºåˆ—è¡¨
        graphs = []
        for smiles in test_smiles:
            graph = graph_processor.smiles_to_graph(smiles)
            if graph is None:
                from torch_geometric.data import Data
                # åˆ›å»ºé»˜è®¤å›¾ï¼Œæ³¨æ„ç‰¹å¾ç»´åº¦åº”è¯¥æ˜¯9
                graph = Data(
                    x=torch.randn(5, 9).to(device),
                    edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long).to(device),
                    edge_attr=torch.randn(4, 3).to(device)
                )
            graphs.append(graph)
        
        with torch.no_grad():
            generated = model.generate(
                scaffold_data=graphs,
                text_data=test_texts,
                scaffold_modality='graph',
                output_modality='smiles',
                num_beams=5,
                temperature=0.8,
                max_length=128
            )
        
        validity = calculate_validity(generated)
        uniqueness = calculate_uniqueness(generated)
        
        logger.info(f"ç”Ÿæˆçš„SMILESç¤ºä¾‹:")
        for i, gen_s in enumerate(generated[:3]):
            logger.info(f"  ç”Ÿæˆ{i+1}: {gen_s}")
        
        logger.info(f"æœ‰æ•ˆç‡: {validity:.2%}")
        logger.info(f"å”¯ä¸€æ€§: {uniqueness:.2%}")
        
        results['graph_to_smiles'] = {
            'validity': validity,
            'uniqueness': uniqueness,
            'examples': generated[:3]
        }
        
    except Exception as e:
        logger.error(f"GRAPHâ†’SMILESå¤±è´¥: {e}")
        results['graph_to_smiles'] = {'error': str(e)}
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"test_results/trained_model_test_{timestamp}.json"
    
    Path("test_results").mkdir(exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    logger.info(f"\n{'='*60}")
    logger.info("æµ‹è¯•å®Œæˆ")
    logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    logger.info(f"{'='*60}")
    
    # æ‰“å°æ€»ç»“
    logger.info("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    for test_name, result in results.items():
        if 'error' in result:
            logger.info(f"  {test_name}: âŒ å¤±è´¥ - {result['error']}")
        else:
            logger.info(f"  {test_name}: âœ… æˆåŠŸ")
            logger.info(f"    - æœ‰æ•ˆç‡: {result['validity']:.2%}")
            logger.info(f"    - å”¯ä¸€æ€§: {result['uniqueness']:.2%}")

if __name__ == "__main__":
    main()