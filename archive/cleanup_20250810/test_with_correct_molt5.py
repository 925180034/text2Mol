#!/usr/bin/env python3
"""
ä½¿ç”¨æ­£ç¡®çš„MolT5-Large-Caption2SMILESæ¨¡å‹æµ‹è¯•
"""

import os
import sys
import torch
import pandas as pd
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥ç»„ä»¶
from scaffold_mol_gen.models.end2end_model import End2EndMolecularGenerator
from transformers import T5ForConditionalGeneration, T5Tokenizer

def main():
    logger.info("="*70)
    logger.info("ä½¿ç”¨æ­£ç¡®çš„MolT5-Large-Caption2SMILESæ¨¡å‹æµ‹è¯•")
    logger.info("="*70)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ–°æ¨¡å‹ï¼Œä½¿ç”¨æ­£ç¡®çš„MolT5
    molt5_path = "/root/autodl-tmp/text2Mol-models/MolT5-Large-Caption2SMILES"
    
    if not Path(molt5_path).exists():
        logger.error(f"MolT5-Largeæ¨¡å‹æœªæ‰¾åˆ°: {molt5_path}")
        logger.error("è¯·ç¡®ä¿ä¸‹è½½äº†æ­£ç¡®çš„æ¨¡å‹")
        return
    
    logger.info(f"åŠ è½½æ­£ç¡®çš„MolT5æ¨¡å‹: {molt5_path}")
    
    # åˆ›å»ºæ¨¡å‹
    model = End2EndMolecularGenerator(
        hidden_size=768,
        molt5_path=molt5_path,  # ä½¿ç”¨æ­£ç¡®çš„MolT5æ¨¡å‹
        device=str(device)
    )
    
    # æ›¿æ¢MolT5ç»„ä»¶ä¸ºæ­£ç¡®çš„ç‰ˆæœ¬
    logger.info("æ›¿æ¢ä¸ºMolT5-Large-Caption2SMILES...")
    molt5_model = T5ForConditionalGeneration.from_pretrained(molt5_path)
    molt5_tokenizer = T5Tokenizer.from_pretrained(molt5_path)
    
    model.generator.molt5 = molt5_model
    model.generator.tokenizer = molt5_tokenizer
    
    # å¦‚æœæœ‰è®­ç»ƒçš„checkpointï¼ŒåŠ è½½æƒé‡ï¼ˆä½†ä¸åŠ è½½é”™è¯¯çš„MolT5éƒ¨åˆ†ï¼‰
    checkpoint_path = "/root/autodl-tmp/text2Mol-outputs/optimized_20250809_105726/best_model.pt"
    if Path(checkpoint_path).exists():
        logger.info(f"åŠ è½½è®­ç»ƒçš„æƒé‡ï¼ˆé™¤MolT5å¤–ï¼‰: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        # åªåŠ è½½éMolT5éƒ¨åˆ†çš„æƒé‡
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
            # è¿‡æ»¤æ‰MolT5çš„æƒé‡
            filtered_state_dict = {k: v for k, v in state_dict.items() 
                                  if 'molt5' not in k.lower()}
            model.load_state_dict(filtered_state_dict, strict=False)
            logger.info("å·²åŠ è½½è®­ç»ƒçš„ç¼–ç å™¨å’Œèåˆå±‚æƒé‡")
    
    model.to(device)
    model.eval()
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_df = pd.read_csv("Datasets/test.csv").head(5)
    test_smiles = test_df['SMILES'].tolist()
    test_texts = test_df['description'].tolist() if 'description' in test_df else test_df['text'].tolist()
    
    logger.info(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_smiles)}")
    
    # æµ‹è¯•SMILES â†’ SMILES
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯• SMILES â†’ SMILES (ä½¿ç”¨æ­£ç¡®çš„MolT5)")
    logger.info("="*60)
    
    try:
        with torch.no_grad():
            generated = model.generate(
                scaffold_data=test_smiles,
                text_data=test_texts,
                scaffold_modality='smiles',
                output_modality='smiles',
                num_beams=5,
                temperature=1.0,
                max_length=128
            )
        
        # è¯„ä¼°
        from rdkit import Chem
        valid_count = 0
        
        logger.info("\nç”Ÿæˆç»“æœ:")
        for i, (input_s, gen_s) in enumerate(zip(test_smiles[:3], generated[:3])):
            mol = Chem.MolFromSmiles(gen_s)
            is_valid = mol is not None
            valid_count += is_valid
            
            logger.info(f"\næ ·æœ¬ {i+1}:")
            logger.info(f"  è¾“å…¥SMILES: {input_s[:50]}...")
            logger.info(f"  è¾“å…¥æ–‡æœ¬: {test_texts[i][:80]}...")
            logger.info(f"  ç”ŸæˆSMILES: {gen_s}")
            logger.info(f"  æœ‰æ•ˆæ€§: {'âœ… æœ‰æ•ˆ' if is_valid else 'âŒ æ— æ•ˆ'}")
        
        validity = sum(1 for s in generated if Chem.MolFromSmiles(s) is not None) / len(generated)
        uniqueness = len(set(generated)) / len(generated)
        
        logger.info(f"\nğŸ“Š ç»Ÿè®¡:")
        logger.info(f"  æœ‰æ•ˆç‡: {validity:.2%}")
        logger.info(f"  å”¯ä¸€æ€§: {uniqueness:.2%}")
        
        if validity > 0:
            logger.info("\nğŸ‰ æˆåŠŸï¼ä½¿ç”¨æ­£ç¡®çš„MolT5æ¨¡å‹å¯ä»¥ç”Ÿæˆæœ‰æ•ˆçš„SMILESï¼")
        else:
            logger.info("\nâš ï¸ ç”Ÿæˆè´¨é‡ä»ç„¶è¾ƒå·®ï¼Œå¯èƒ½éœ€è¦å¾®è°ƒMolT5æ¨¡å‹")
            
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
    
    logger.info("\n" + "="*70)
    logger.info("æµ‹è¯•å®Œæˆ")
    logger.info("="*70)

if __name__ == "__main__":
    main()