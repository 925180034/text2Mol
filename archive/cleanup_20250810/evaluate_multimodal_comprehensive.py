#!/usr/bin/env python3
"""
å¤šæ¨¡æ€åˆ†å­ç”Ÿæˆç³»ç»Ÿå…¨é¢è¯„ä¼°
æµ‹è¯•9ç§è¾“å…¥è¾“å‡ºç»„åˆï¼Œè®¡ç®—10ç§è¯„ä¼°æŒ‡æ ‡
"""

import os
import sys
import torch
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json
from tqdm import tqdm
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/root/text2Mol/scaffold-mol-generation')

from rdkit import Chem
from rdkit.Chem import Descriptors, AllChem, DataStructs
from rdkit import RDLogger
RDLogger.DisableLog('rdApp.*')

# å¯¼å…¥æ¨¡å‹å’Œæ•°æ®å¤„ç†
from scaffold_mol_gen.models.end2end_model import End2EndMolecularGenerator

# å¯¼å…¥è¯„ä¼°æŒ‡æ ‡
from evaluation_metrics import (
    calculate_validity,
    calculate_uniqueness,
    calculate_novelty,
    calculate_bleu_score,
    calculate_exact_match,
    calculate_levenshtein_distance,
    calculate_fingerprint_similarity,
    calculate_fcd
)
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultiModalEvaluator:
    """å¤šæ¨¡æ€åˆ†å­ç”Ÿæˆè¯„ä¼°å™¨"""
    
    def __init__(self, model_path: str, device: str = 'cuda'):
        self.device = device
        self.model_path = model_path
        
        # å®šä¹‰9ç§è¾“å…¥è¾“å‡ºç»„åˆï¼ˆå®é™…ä¸Šæ˜¯7ç§ï¼Œä½†æˆ‘ä»¬æµ‹è¯•æ‰€æœ‰å¯èƒ½çš„ï¼‰
        self.io_combinations = [
            # å·²å®ç°çš„ç»„åˆ (è¾“å‡ºSMILES)
            ('smiles', 'smiles', 'âœ…'),  # Scaffold(SMILES) + Text â†’ SMILES
            ('graph', 'smiles', 'âœ…'),   # Scaffold(Graph) + Text â†’ SMILES
            ('image', 'smiles', 'âœ…'),   # Scaffold(Image) + Text â†’ SMILES
            
            # å¾…å®ç°çš„ç»„åˆ (éœ€è¦é¢å¤–è§£ç å™¨)
            ('smiles', 'graph', 'ğŸ”„'),   # Scaffold(SMILES) + Text â†’ Graph
            ('smiles', 'image', 'ğŸ”„'),   # Scaffold(SMILES) + Text â†’ Image
            ('graph', 'graph', 'ğŸ”„'),    # Scaffold(Graph) + Text â†’ Graph
            ('graph', 'image', 'ğŸ”„'),    # Scaffold(Graph) + Text â†’ Image
            ('image', 'graph', 'ğŸ”„'),    # Scaffold(Image) + Text â†’ Graph
            ('image', 'image', 'ğŸ”„'),    # Scaffold(Image) + Text â†’ Image
        ]
        
        # 10ç§è¯„ä¼°æŒ‡æ ‡
        self.metrics_list = [
            'validity',           # 1. æœ‰æ•ˆæ€§
            'uniqueness',         # 2. å”¯ä¸€æ€§
            'novelty',           # 3. æ–°é¢–æ€§
            'bleu_score',        # 4. BLEUåˆ†æ•°
            'exact_match',       # 5. ç²¾ç¡®åŒ¹é…
            'levenshtein_dist',  # 6. ç¼–è¾‘è·ç¦»
            'maccs_similarity',  # 7. MACCSæŒ‡çº¹ç›¸ä¼¼åº¦
            'morgan_similarity', # 8. MorganæŒ‡çº¹ç›¸ä¼¼åº¦
            'rdkit_similarity',  # 9. RDKitæŒ‡çº¹ç›¸ä¼¼åº¦
            'fcd_score'         # 10. FCDåˆ†æ•°
        ]
        
        logger.info(f"åˆå§‹åŒ–è¯„ä¼°å™¨ - è®¾å¤‡: {device}")
        logger.info(f"æ¨¡å‹è·¯å¾„: {model_path}")
        
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        logger.info("åŠ è½½æ¨¡å‹...")
        
        # åˆ›å»ºæ¨¡å‹
        self.model = End2EndMolecularGenerator(
            hidden_size=768,
            molt5_path="/root/autodl-tmp/text2Mol-models/molt5-base",
            freeze_encoders=True,
            freeze_molt5=True,
            device=self.device
        )
        
        # åŠ è½½æƒé‡
        if Path(self.model_path).exists():
            checkpoint = torch.load(self.model_path, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ - Epoch: {checkpoint.get('epoch', 'N/A')}")
        else:
            logger.warning(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            
        self.model.eval()
        self.model.to(self.device)
        
    def load_test_data(self, test_file: str = "Datasets/test.csv", sample_size: int = 100):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        logger.info(f"åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")
        
        df = pd.read_csv(test_file)
        if sample_size and sample_size < len(df):
            df = df.sample(n=sample_size, random_state=42)
            logger.info(f"é‡‡æ · {sample_size} æ¡æ•°æ®è¿›è¡Œæµ‹è¯•")
            
        self.test_data = df
        logger.info(f"æµ‹è¯•æ•°æ®é‡: {len(self.test_data)}")
        
        return df
    
    def evaluate_io_combination(self, scaffold_modality: str, output_modality: str) -> Dict:
        """è¯„ä¼°å•ä¸ªè¾“å…¥è¾“å‡ºç»„åˆ"""
        results = {
            'scaffold_modality': scaffold_modality,
            'output_modality': output_modality,
            'metrics': {},
            'examples': []
        }
        
        # åªè¯„ä¼°è¾“å‡ºä¸ºSMILESçš„ç»„åˆï¼ˆå…¶ä»–ç»„åˆéœ€è¦é¢å¤–è§£ç å™¨ï¼‰
        if output_modality != 'smiles':
            logger.info(f"â­ï¸ è·³è¿‡æœªå®ç°çš„ç»„åˆ: {scaffold_modality} â†’ {output_modality}")
            results['status'] = 'not_implemented'
            return results
            
        logger.info(f"è¯„ä¼°ç»„åˆ: Scaffold({scaffold_modality}) + Text â†’ {output_modality}")
        
        generated_smiles = []
        target_smiles = []
        
        # æ‰¹é‡ç”Ÿæˆ
        batch_size = 8
        for i in tqdm(range(0, len(self.test_data), batch_size), desc=f"{scaffold_modality}â†’{output_modality}"):
            batch = self.test_data.iloc[i:i+batch_size]
            
            # å‡†å¤‡è¾“å…¥ - ä½¿ç”¨æ­£ç¡®çš„åˆ—å
            # test.csv ä½¿ç”¨ 'SMILES' ä½œä¸ºscaffoldï¼Œ'description' ä½œä¸ºæ–‡æœ¬
            smiles_list = batch['SMILES'].tolist()
            text_list = batch['description'].tolist()
            target_list = batch['SMILES'].tolist()  # ç›®æ ‡ä¹Ÿæ˜¯SMILES
            
            # æ ¹æ®scaffoldæ¨¡æ€è½¬æ¢è¾“å…¥æ•°æ®
            if scaffold_modality == 'smiles':
                scaffold_list = smiles_list
            elif scaffold_modality == 'graph':
                # å°†SMILESè½¬æ¢ä¸ºå›¾
                from scaffold_mol_gen.data.multimodal_preprocessor import MultiModalPreprocessor
                preprocessor = MultiModalPreprocessor()
                scaffold_list = []
                for smiles in smiles_list:
                    graph = preprocessor.smiles_to_graph(smiles)
                    if graph is not None:
                        scaffold_list.append(graph)
                    else:
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªæ ·æœ¬
                        logger.warning(f"æ— æ³•å°†SMILESè½¬æ¢ä¸ºå›¾: {smiles}")
                        continue
                if not scaffold_list:
                    logger.error("æ‰€æœ‰SMILESåˆ°å›¾çš„è½¬æ¢éƒ½å¤±è´¥äº†")
                    continue
            elif scaffold_modality == 'image':
                # å°†SMILESè½¬æ¢ä¸ºå›¾åƒ
                from scaffold_mol_gen.data.multimodal_preprocessor import MultiModalPreprocessor
                preprocessor = MultiModalPreprocessor()
                scaffold_list = []
                for smiles in smiles_list:
                    image = preprocessor.smiles_to_image(smiles)
                    if image is not None:
                        # è½¬æ¢ä¸ºtensor
                        import torchvision.transforms as transforms
                        transform = transforms.Compose([
                            transforms.ToPILImage(),
                            transforms.Resize((224, 224)),
                            transforms.ToTensor(),
                            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                              std=[0.229, 0.224, 0.225])
                        ])
                        if isinstance(image, np.ndarray):
                            image_tensor = transform(image)
                            scaffold_list.append(image_tensor)
                    else:
                        logger.warning(f"æ— æ³•å°†SMILESè½¬æ¢ä¸ºå›¾åƒ: {smiles}")
                        continue
                if not scaffold_list:
                    logger.error("æ‰€æœ‰SMILESåˆ°å›¾åƒçš„è½¬æ¢éƒ½å¤±è´¥äº†")
                    continue
                # å°†å›¾åƒåˆ—è¡¨è½¬æ¢ä¸ºæ‰¹æ¬¡tensor
                scaffold_list = torch.stack(scaffold_list).to(self.device)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„scaffoldæ¨¡æ€: {scaffold_modality}")
            
            try:
                with torch.no_grad():
                    # ç”ŸæˆSMILES
                    output = self.model.generate(
                        scaffold_data=scaffold_list,
                        text_data=text_list,
                        scaffold_modality=scaffold_modality,
                        output_modality=output_modality,
                        num_beams=5,
                        temperature=0.8,
                        max_length=128
                    )
                    
                    if isinstance(output, list):
                        generated_smiles.extend(output)
                    else:
                        generated_smiles.extend(output.tolist() if hasattr(output, 'tolist') else [output])
                        
                    target_smiles.extend(target_list)
                    
                    # ä¿å­˜å‰5ä¸ªä¾‹å­
                    if len(results['examples']) < 5:
                        for j in range(min(len(scaffold_list), 5 - len(results['examples']))):
                            results['examples'].append({
                                'scaffold': scaffold_list[j],
                                'text': text_list[j][:50] + '...' if len(text_list[j]) > 50 else text_list[j],
                                'target': target_list[j],
                                'generated': output[j] if isinstance(output, list) else str(output)
                            })
                            
            except Exception as e:
                logger.error(f"ç”Ÿæˆé”™è¯¯: {e}")
                continue
        
        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        if generated_smiles and target_smiles:
            results['metrics'] = self.calculate_all_metrics(generated_smiles, target_smiles)
            results['status'] = 'success'
        else:
            results['status'] = 'failed'
            
        return results
    
    def calculate_all_metrics(self, generated: List[str], target: List[str]) -> Dict:
        """è®¡ç®—æ‰€æœ‰10ç§è¯„ä¼°æŒ‡æ ‡"""
        metrics = {}
        
        try:
            # 1. æœ‰æ•ˆæ€§
            metrics['validity'] = calculate_validity(generated)
            
            # 2. å”¯ä¸€æ€§
            metrics['uniqueness'] = calculate_uniqueness(generated)
            
            # 3. æ–°é¢–æ€§
            metrics['novelty'] = calculate_novelty(generated, target)
            
            # 4. BLEUåˆ†æ•°
            metrics['bleu_score'] = calculate_bleu_score(generated, target)
            
            # 5. ç²¾ç¡®åŒ¹é…
            metrics['exact_match'] = calculate_exact_match(generated, target)
            
            # 6. ç¼–è¾‘è·ç¦»
            metrics['levenshtein_dist'] = calculate_levenshtein_distance(generated, target)
            
            # 7-9. æŒ‡çº¹ç›¸ä¼¼åº¦
            metrics['maccs_similarity'] = calculate_fingerprint_similarity(
                generated, target, fingerprint_type='maccs'
            )
            metrics['morgan_similarity'] = calculate_fingerprint_similarity(
                generated, target, fingerprint_type='morgan'
            )
            metrics['rdkit_similarity'] = calculate_fingerprint_similarity(
                generated, target, fingerprint_type='rdkit'
            )
            
            # 10. FCDåˆ†æ•° (éœ€è¦é¢„è®­ç»ƒçš„ChemNetæ¨¡å‹ï¼Œå¯èƒ½è¾ƒæ…¢)
            try:
                metrics['fcd_score'] = calculate_fcd(generated, target)
            except:
                metrics['fcd_score'] = -1  # FCDè®¡ç®—å¤±è´¥æ—¶è¿”å›-1
                
        except Exception as e:
            logger.error(f"æŒ‡æ ‡è®¡ç®—é”™è¯¯: {e}")
            
        return metrics
    
    def run_comprehensive_evaluation(self):
        """è¿è¡Œå…¨é¢è¯„ä¼°"""
        logger.info("=" * 80)
        logger.info("ğŸ”¬ å¤šæ¨¡æ€åˆ†å­ç”Ÿæˆç³»ç»Ÿå…¨é¢è¯„ä¼°")
        logger.info("=" * 80)
        
        # åŠ è½½æ¨¡å‹
        self.load_model()
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        self.load_test_data(sample_size=100)  # ä½¿ç”¨100ä¸ªæ ·æœ¬è¿›è¡Œå¿«é€Ÿè¯„ä¼°
        
        # å­˜å‚¨æ‰€æœ‰ç»“æœ
        all_results = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'model_path': self.model_path,
            'test_samples': len(self.test_data),
            'combinations': []
        }
        
        # è¯„ä¼°æ¯ä¸ªè¾“å…¥è¾“å‡ºç»„åˆ
        for scaffold_mod, output_mod, status in self.io_combinations:
            logger.info(f"\n{'='*60}")
            logger.info(f"æµ‹è¯•ç»„åˆ {status}: Scaffold({scaffold_mod}) + Text â†’ {output_mod}")
            logger.info(f"{'='*60}")
            
            result = self.evaluate_io_combination(scaffold_mod, output_mod)
            all_results['combinations'].append(result)
            
            # æ‰“å°ç»“æœ
            if result['status'] == 'success':
                self.print_metrics(result['metrics'])
                if result['examples']:
                    self.print_examples(result['examples'])
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report(all_results)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        output_file = f"evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w') as f:
            json.dump(all_results, f, indent=2, default=str)
        logger.info(f"\nğŸ“Š è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_file}")
        
        return all_results
    
    def print_metrics(self, metrics: Dict):
        """æ‰“å°è¯„ä¼°æŒ‡æ ‡"""
        logger.info("\nğŸ“ˆ è¯„ä¼°æŒ‡æ ‡:")
        logger.info("-" * 40)
        
        for i, (key, value) in enumerate(metrics.items(), 1):
            if isinstance(value, float):
                logger.info(f"{i:2}. {key:20s}: {value:.4f}")
            else:
                logger.info(f"{i:2}. {key:20s}: {value}")
    
    def print_examples(self, examples: List[Dict]):
        """æ‰“å°ç”Ÿæˆç¤ºä¾‹"""
        logger.info("\nğŸ” ç”Ÿæˆç¤ºä¾‹:")
        logger.info("-" * 40)
        
        for i, ex in enumerate(examples[:3], 1):
            logger.info(f"\nç¤ºä¾‹ {i}:")
            logger.info(f"  Scaffold: {ex['scaffold'][:50]}...")
            logger.info(f"  æ–‡æœ¬: {ex['text']}")
            logger.info(f"  ç›®æ ‡: {ex['target'][:50]}...")
            logger.info(f"  ç”Ÿæˆ: {ex['generated'][:50]}...")
            
            # éªŒè¯ç”Ÿæˆçš„SMILES
            mol = Chem.MolFromSmiles(ex['generated'])
            if mol:
                logger.info(f"  âœ… æœ‰æ•ˆSMILES")
            else:
                logger.info(f"  âŒ æ— æ•ˆSMILES")
    
    def generate_summary_report(self, all_results: Dict):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š è¯„ä¼°æ€»ç»“æŠ¥å‘Š")
        logger.info("=" * 80)
        
        # ç»Ÿè®¡å®ç°çš„ç»„åˆ
        implemented = [r for r in all_results['combinations'] if r['status'] == 'success']
        
        if implemented:
            logger.info(f"\nâœ… æˆåŠŸè¯„ä¼°çš„ç»„åˆ: {len(implemented)}/9")
            
            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            avg_metrics = {}
            for metric_name in self.metrics_list:
                values = [r['metrics'].get(metric_name, 0) for r in implemented if metric_name in r['metrics']]
                if values:
                    avg_metrics[metric_name] = np.mean(values)
            
            logger.info("\nğŸ“Š å¹³å‡æ€§èƒ½æŒ‡æ ‡:")
            logger.info("-" * 40)
            
            # é‡ç‚¹æŒ‡æ ‡
            key_metrics = ['validity', 'uniqueness', 'novelty', 'exact_match', 'morgan_similarity']
            for metric in key_metrics:
                if metric in avg_metrics:
                    value = avg_metrics[metric]
                    # æ ¹æ®æŒ‡æ ‡ç±»å‹æ˜¾ç¤ºä¸åŒçš„è¡¨æƒ…
                    if metric == 'validity':
                        emoji = "ğŸ¯" if value > 0.6 else "âš ï¸"
                    elif metric == 'uniqueness':
                        emoji = "ğŸ’" if value > 0.8 else "ğŸ“Š"
                    elif metric == 'novelty':
                        emoji = "ğŸŒŸ" if value > 0.5 else "ğŸ“ˆ"
                    elif metric == 'exact_match':
                        emoji = "âœ…" if value > 0.3 else "ğŸ“Š"
                    else:
                        emoji = "ğŸ“Š"
                    
                    logger.info(f"{emoji} {metric:20s}: {value:.4f} ({value*100:.2f}%)")
            
            # å…¶ä»–æŒ‡æ ‡
            logger.info("\nğŸ“ˆ å…¶ä»–æŒ‡æ ‡:")
            for metric, value in avg_metrics.items():
                if metric not in key_metrics:
                    logger.info(f"   {metric:20s}: {value:.4f}")
        
        # æ€»ç»“
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ¯ å…³é”®å‘ç°:")
        
        if implemented:
            validity_scores = [r['metrics'].get('validity', 0) for r in implemented]
            avg_validity = np.mean(validity_scores) if validity_scores else 0
            
            if avg_validity > 0.6:
                logger.info(f"âœ… SMILESæœ‰æ•ˆæ€§è¾¾åˆ° {avg_validity*100:.1f}% - æ˜¾è‘—æ”¹è¿›ï¼")
            else:
                logger.info(f"âš ï¸ SMILESæœ‰æ•ˆæ€§ä¸º {avg_validity*100:.1f}% - éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
                
            # æœ€ä½³ç»„åˆ
            best_combo = max(implemented, key=lambda x: x['metrics'].get('validity', 0))
            logger.info(f"ğŸ† æœ€ä½³ç»„åˆ: {best_combo['scaffold_modality']} â†’ {best_combo['output_modality']}")
            logger.info(f"   æœ‰æ•ˆæ€§: {best_combo['metrics'].get('validity', 0)*100:.1f}%")
        
        logger.info("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¤šæ¨¡æ€åˆ†å­ç”Ÿæˆç³»ç»Ÿå…¨é¢è¯„ä¼°')
    parser.add_argument('--model-path', type=str,
                       default='/root/autodl-tmp/text2Mol-outputs/optimized_20250809_105726/best_model.pt',
                       help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--test-file', type=str,
                       default='Datasets/test.csv',
                       help='æµ‹è¯•æ•°æ®æ–‡ä»¶')
    parser.add_argument('--sample-size', type=int, default=100,
                       help='æµ‹è¯•æ ·æœ¬æ•°é‡')
    parser.add_argument('--device', type=str, default='cuda',
                       help='è®¾å¤‡')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = MultiModalEvaluator(
        model_path=args.model_path,
        device=args.device
    )
    
    # è¿è¡Œè¯„ä¼°
    results = evaluator.run_comprehensive_evaluation()
    
    logger.info("\nâœ… è¯„ä¼°å®Œæˆï¼")
    

if __name__ == "__main__":
    main()