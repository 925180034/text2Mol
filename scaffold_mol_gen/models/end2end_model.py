"""
ç«¯åˆ°ç«¯çš„å¤šæ¨¡æ€åˆ†å­ç”Ÿæˆæ¨¡å‹
æ•´åˆç¼–ç å™¨ã€èåˆå±‚å’ŒMolT5ç”Ÿæˆå™¨
"""

import torch
import torch.nn as nn
from typing import Dict, List, Optional, Tuple, Union, Any
import logging
from pathlib import Path

# å¯¼å…¥æ‰€æœ‰ç»„ä»¶
from .encoders import MultiModalEncoder
from .fusion_simplified import ModalFusionLayer, MultiModalFusionLayer
from .molt5_adapter import MolT5Generator
from .output_decoders import OutputDecoder

logger = logging.getLogger(__name__)


class End2EndMolecularGenerator(nn.Module):
    """
    å®Œæ•´çš„ç«¯åˆ°ç«¯åˆ†å­ç”Ÿæˆæ¨¡å‹
    æ”¯æŒå¤šç§è¾“å…¥æ¨¡æ€ç»„åˆå’Œè¾“å‡ºæ¨¡æ€
    """
    
    def __init__(self,
                 hidden_size: int = 768,
                 molt5_path: str = "/root/autodl-tmp/text2Mol-models/molt5-base",
                 use_scibert: bool = False,
                 freeze_encoders: bool = True,
                 freeze_molt5: bool = True,
                 fusion_type: str = 'both',
                 device: str = 'cuda'):
        """
        Args:
            hidden_size: ç»Ÿä¸€çš„éšè—å±‚ç»´åº¦
            molt5_path: MolT5æ¨¡å‹è·¯å¾„
            use_scibert: æ˜¯å¦ä½¿ç”¨SciBERT
            freeze_encoders: æ˜¯å¦å†»ç»“ç¼–ç å™¨
            freeze_molt5: æ˜¯å¦å†»ç»“MolT5
            fusion_type: èåˆç±»å‹ ('attention', 'gated', 'both')
            device: è®¾å¤‡
        """
        super().__init__()
        
        self.hidden_size = hidden_size
        self.device = device
        
        logger.info("åˆå§‹åŒ–ç«¯åˆ°ç«¯åˆ†å­ç”Ÿæˆæ¨¡å‹...")
        
        # 1. å¤šæ¨¡æ€ç¼–ç å™¨
        logger.info("åˆ›å»ºå¤šæ¨¡æ€ç¼–ç å™¨...")
        self.encoder = MultiModalEncoder(
            hidden_size=hidden_size,
            use_scibert=use_scibert,
            freeze_backbones=freeze_encoders,
            device=device
        )
        
        # 2. æ¨¡æ€èåˆå±‚
        logger.info(f"åˆ›å»ºèåˆå±‚ (type={fusion_type})...")
        self.fusion = MultiModalFusionLayer(
            hidden_size=hidden_size,
            num_heads=8,
            dropout=0.1
        )
        
        # 3. MolT5ç”Ÿæˆå™¨
        logger.info("åˆ›å»ºMolT5ç”Ÿæˆå™¨...")
        self.generator = MolT5Generator(
            molt5_path=molt5_path,
            adapter_config={
                'input_hidden_size': hidden_size,
                'num_layers': 2,
                'num_heads': 8
            },
            freeze_molt5=freeze_molt5,
            device=device
        )
        
        # 4. è¾“å‡ºè§£ç å™¨ï¼ˆç”¨äºSMILESâ†’å…¶ä»–æ¨¡æ€è½¬æ¢ï¼‰
        logger.info("åˆ›å»ºè¾“å‡ºè§£ç å™¨...")
        self.output_decoder = OutputDecoder()
        self.output_modalities = ['smiles', 'graph', 'image']
        
        # 5. ç›´æ¥è§£ç å™¨ï¼ˆç”¨äº768ç»´ç‰¹å¾â†’å…¶ä»–æ¨¡æ€ï¼‰
        from .graph_decoder import MolecularGraphDecoder
        from .image_decoder import MolecularImageDecoder
        
        self.direct_graph_decoder = MolecularGraphDecoder(
            input_dim=hidden_size,
            max_atoms=100,
            hidden_dim=512,
            dropout=0.1
        ).to(device)
        
        self.direct_image_decoder = MolecularImageDecoder(
            input_dim=hidden_size,
            image_size=224,
            channels=3,
            hidden_dim=512,
            dropout=0.1
        ).to(device)
        
        logger.info("ç«¯åˆ°ç«¯æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        
    def forward(self,
                scaffold_data: Any,
                text_data: Union[str, List[str]],
                scaffold_modality: str = 'smiles',
                target_smiles: Optional[List[str]] = None,
                output_modality: str = 'smiles') -> Dict[str, Any]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            scaffold_data: Scaffoldæ•°æ®ï¼ˆSMILESå­—ç¬¦ä¸²ã€å›¾æˆ–å›¾åƒï¼‰
            text_data: æ–‡æœ¬æè¿°
            scaffold_modality: Scaffoldè¾“å…¥æ¨¡æ€ ('smiles', 'graph', 'image')
            target_smiles: ç›®æ ‡SMILESï¼ˆè®­ç»ƒæ—¶æä¾›ï¼‰
            output_modality: è¾“å‡ºæ¨¡æ€ ('smiles', 'graph', 'image')
            
        Returns:
            åŒ…å«ç”Ÿæˆç»“æœå’Œä¸­é—´ä¿¡æ¯çš„å­—å…¸
        """
        # 1. ç¼–ç è¾“å…¥
        scaffold_features, text_features = self.encoder(
            scaffold_data=scaffold_data,
            text_data=text_data,
            scaffold_modality=scaffold_modality
        )
        
        # 2. æ¨¡æ€èåˆ
        fused_features, fusion_info = self.fusion(
            scaffold_features=scaffold_features,
            text_features=text_features,
            scaffold_modality=scaffold_modality
        )
        
        # 3. ç”Ÿæˆè¾“å‡º
        output_dict = {}
        
        # é¦–å…ˆæ€»æ˜¯ç”ŸæˆSMILESï¼ˆä½œä¸ºåŸºç¡€è¡¨ç¤ºï¼‰
        generator_output = self.generator(
            fused_features=fused_features,
            target_smiles=target_smiles
        )
        output_dict.update(generator_output)
        
        # å¦‚æœéœ€è¦å…¶ä»–æ¨¡æ€ï¼Œæ”¯æŒä¸¤ç§æ–¹å¼ï¼šç›´æ¥è§£ç æˆ–è½¬æ¢SMILES
        if output_modality != 'smiles':
            # æ–¹å¼1ï¼šç›´æ¥ä»èåˆç‰¹å¾ç”Ÿæˆï¼ˆè®­ç»ƒæ—¶ä½¿ç”¨ï¼‰
            if output_modality == 'graph':
                direct_graph = self.direct_graph_decoder(fused_features)
                output_dict['direct_graph_predictions'] = direct_graph
            elif output_modality == 'image':
                direct_image = self.direct_image_decoder(fused_features)
                output_dict['direct_image'] = direct_image
            
            # æ–¹å¼2ï¼šè½¬æ¢SMILESï¼ˆæ¨ç†æ—¶ä½¿ç”¨ï¼‰
            if 'generated_smiles' in output_dict:
                # æ¨ç†æ¨¡å¼ï¼šè½¬æ¢ç”Ÿæˆçš„SMILES
                decoded_output = self.output_decoder.decode(
                    output_dict['generated_smiles'], 
                    output_modality
                )
                output_dict[f'generated_{output_modality}'] = decoded_output
            elif target_smiles is not None:
                # è®­ç»ƒæ¨¡å¼ï¼šè½¬æ¢ç›®æ ‡SMILESç”¨äºå¯è§†åŒ–
                decoded_output = self.output_decoder.decode(
                    target_smiles, 
                    output_modality
                )
                output_dict[f'target_{output_modality}'] = decoded_output
        
        # 4. æ·»åŠ ä¸­é—´ä¿¡æ¯
        output_dict['fusion_info'] = fusion_info
        output_dict['scaffold_modality'] = scaffold_modality
        output_dict['output_modality'] = output_modality
        output_dict['fused_features'] = fused_features  # æ·»åŠ èåˆç‰¹å¾ä¾›è®­ç»ƒä½¿ç”¨
        
        return output_dict
    
    def generate(self,
                 scaffold_data: Any,
                 text_data: Union[str, List[str]],
                 scaffold_modality: str = 'smiles',
                 output_modality: str = 'smiles',
                 num_beams: int = 5,
                 temperature: float = 0.8,
                 max_length: int = 128,
                 num_return_sequences: int = 1) -> Union[List[str], Any]:
        """
        ç”Ÿæˆåˆ†å­
        
        Args:
            scaffold_data: Scaffoldè¾“å…¥
            text_data: æ–‡æœ¬æè¿°
            scaffold_modality: Scaffoldæ¨¡æ€
            output_modality: è¾“å‡ºæ¨¡æ€
            num_beams: Beam searchå¤§å°
            temperature: é‡‡æ ·æ¸©åº¦
            max_length: æœ€å¤§é•¿åº¦
            num_return_sequences: è¿”å›åºåˆ—æ•°
            
        Returns:
            ç”Ÿæˆçš„åˆ†å­ï¼ˆSMILES/Graph/Imageï¼‰
        """
        # 1. ç¼–ç å’Œèåˆ
        scaffold_features, text_features = self.encoder(
            scaffold_data=scaffold_data,
            text_data=text_data,
            scaffold_modality=scaffold_modality
        )
        
        fused_features, _ = self.fusion(
            scaffold_features=scaffold_features,
            text_features=text_features,
            scaffold_modality=scaffold_modality
        )
        
        # 2. æ ¹æ®è¾“å‡ºæ¨¡æ€ç”Ÿæˆ
        # é¦–å…ˆç”ŸæˆSMILESï¼ˆä½œä¸ºä¸­é—´è¡¨ç¤ºï¼‰
        smiles_output = self.generator.generate(
            fused_features=fused_features,
            num_beams=num_beams,
            temperature=temperature,
            max_length=max_length,
            num_return_sequences=num_return_sequences
        )
        
        # 3. æ ¹æ®ç›®æ ‡æ¨¡æ€è¿›è¡Œç”Ÿæˆ/è§£ç 
        if output_modality == 'smiles':
            return smiles_output
        elif output_modality == 'graph':
            # ç›´æ¥ä»èåˆç‰¹å¾ç”Ÿæˆå›¾
            graph_predictions = self.direct_graph_decoder(fused_features)
            decoded_graphs = self.direct_graph_decoder.decode_to_graphs(graph_predictions)
            return decoded_graphs
        elif output_modality == 'image':
            # ç›´æ¥ä»èåˆç‰¹å¾ç”Ÿæˆå›¾åƒ
            generated_images = self.direct_image_decoder(fused_features)
            processed_images = self.direct_image_decoder.postprocess_images(generated_images, to_pil=True)
            return processed_images
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šé€šè¿‡SMILESè½¬æ¢
            return self.output_decoder.decode(smiles_output, output_modality)
    
    def compute_loss(self,
                     scaffold_data: Any,
                     text_data: Union[str, List[str]],
                     target_smiles: List[str],
                     scaffold_modality: str = 'smiles') -> torch.Tensor:
        """
        è®¡ç®—è®­ç»ƒæŸå¤±
        
        Args:
            scaffold_data: Scaffoldè¾“å…¥
            text_data: æ–‡æœ¬æè¿°
            target_smiles: ç›®æ ‡SMILES
            scaffold_modality: Scaffoldæ¨¡æ€
            
        Returns:
            loss: è®­ç»ƒæŸå¤±
        """
        output_dict = self.forward(
            scaffold_data=scaffold_data,
            text_data=text_data,
            scaffold_modality=scaffold_modality,
            target_smiles=target_smiles,
            output_modality='smiles'
        )
        
        return output_dict['loss']
    
    def get_supported_combinations(self) -> List[Tuple[str, str]]:
        """
        è·å–æ”¯æŒçš„è¾“å…¥è¾“å‡ºç»„åˆ
        
        Returns:
            æ”¯æŒçš„(scaffold_modality, output_modality)ç»„åˆåˆ—è¡¨
        """
        scaffold_modalities = ['smiles', 'graph', 'image']
        output_modalities = self.output_modalities
        
        combinations = []
        for scaffold_mod in scaffold_modalities:
            for output_mod in output_modalities:
                combinations.append((scaffold_mod, output_mod))
        
        return combinations


def test_end2end_model():
    """æµ‹è¯•ç«¯åˆ°ç«¯æ¨¡å‹"""
    import torch
    from rdkit import Chem
    
    # è®¾ç½®è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print("=" * 50)
    
    # æ£€æŸ¥MolT5æ¨¡å‹
    molt5_path = "/root/autodl-tmp/text2Mol-models/molt5-base"
    if not Path(molt5_path).exists():
        print(f"âš ï¸ MolT5æ¨¡å‹æœªæ‰¾åˆ°: {molt5_path}")
        print("è¯·å…ˆä¸‹è½½MolT5æ¨¡å‹")
        return
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºç«¯åˆ°ç«¯æ¨¡å‹...")
    model = End2EndMolecularGenerator(
        hidden_size=768,
        molt5_path=molt5_path,
        use_scibert=False,
        freeze_encoders=True,
        freeze_molt5=True,
        fusion_type='both',
        device=device
    )
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    print("\nå‡†å¤‡æµ‹è¯•æ•°æ®...")
    # Scaffold SMILES (è‹¯ç¯)
    scaffold_smiles = "c1ccccc1"
    # æ–‡æœ¬æè¿°
    text_description = "Anti-inflammatory drug with carboxylic acid group"
    
    print(f"Scaffold SMILES: {scaffold_smiles}")
    print(f"æ–‡æœ¬æè¿°: {text_description}")
    
    # æµ‹è¯•ä¸åŒçš„Scaffoldè¾“å…¥æ¨¡æ€
    print("\n" + "=" * 50)
    print("æµ‹è¯•ä¸åŒçš„è¾“å…¥æ¨¡æ€ç»„åˆ")
    print("=" * 50)
    
    for scaffold_modality in ['smiles', 'graph', 'image']:
        print(f"\n### æµ‹è¯• Scaffold({scaffold_modality}) + Text â†’ SMILES")
        
        try:
            # ç”Ÿæˆåˆ†å­
            generated_smiles = model.generate(
                scaffold_data=scaffold_smiles,
                text_data=text_description,
                scaffold_modality=scaffold_modality,
                output_modality='smiles',
                num_beams=3,
                temperature=0.8,
                max_length=64,
                num_return_sequences=1
            )
            
            print(f"ç”Ÿæˆçš„SMILES: {generated_smiles[0]}")
            
            # éªŒè¯ç”Ÿæˆçš„SMILES
            mol = Chem.MolFromSmiles(generated_smiles[0])
            if mol is not None:
                print("âœ… ç”Ÿæˆçš„SMILESæœ‰æ•ˆ")
            else:
                print("âš ï¸ ç”Ÿæˆçš„SMILESæ— æ•ˆ")
                
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
    
    # æµ‹è¯•è®­ç»ƒæ¨¡å¼
    print("\n" + "=" * 50)
    print("æµ‹è¯•è®­ç»ƒæ¨¡å¼")
    print("=" * 50)
    
    # æ‰¹é‡æ•°æ®
    batch_scaffold = [scaffold_smiles, "c1ccc2c(c1)cccc2"]  # è‹¯ç¯å’Œè˜ç¯
    batch_text = [
        "Anti-inflammatory drug",
        "Antibiotic compound"
    ]
    batch_target = ["CC(=O)Oc1ccccc1C(=O)O", "CC1CC(C)CN1C(=O)C"]  # é˜¿å¸åŒ¹æ—å’Œå…¶ä»–
    
    try:
        loss = model.compute_loss(
            scaffold_data=batch_scaffold,
            text_data=batch_text,
            target_smiles=batch_target,
            scaffold_modality='smiles'
        )
        
        print(f"è®­ç»ƒLoss: {loss.item():.4f}")
        print("âœ… è®­ç»ƒæ¨¡å¼æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ¨¡å¼é”™è¯¯: {e}")
    
    # æ˜¾ç¤ºæ”¯æŒçš„ç»„åˆ
    print("\n" + "=" * 50)
    print("æ”¯æŒçš„è¾“å…¥è¾“å‡ºç»„åˆ")
    print("=" * 50)
    
    combinations = model.get_supported_combinations()
    for i, (scaffold_mod, output_mod) in enumerate(combinations, 1):
        status = "âœ…" if output_mod == 'smiles' else "ğŸ”„"
        print(f"{i}. Scaffold({scaffold_mod}) + Text â†’ {output_mod} {status}")
    
    print("\nâœ… - å·²å®ç°  ğŸ”„ - å¼€å‘ä¸­")
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 50)


if __name__ == "__main__":
    test_end2end_model()