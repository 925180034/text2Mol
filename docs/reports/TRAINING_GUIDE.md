# ğŸš€ å¤šæ¨¡æ€åˆ†å­ç”Ÿæˆæ¨¡å‹è®­ç»ƒæŒ‡å—

## ğŸ“‹ å‰ç½®å‡†å¤‡

### 1. ç¯å¢ƒæ£€æŸ¥
```bash
# æ£€æŸ¥GPU
nvidia-smi

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls -lh Datasets/*.csv

# æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹
ls -lh /root/autodl-tmp/text2Mol-models/
```

## ğŸ¯ è®­ç»ƒæ–¹æ¡ˆé€‰æ‹©

### æ–¹æ¡ˆ1ï¼šå¿«é€Ÿå¯åŠ¨ï¼ˆæ¨èï¼‰
æœ€ç®€å•çš„æ–¹å¼ï¼Œä¸€é”®å¯åŠ¨åå°è®­ç»ƒï¼š
```bash
./start_background_training.sh
```

### æ–¹æ¡ˆ2ï¼šäº¤äº’å¼å¯åŠ¨
æä¾›å¤šç§è®­ç»ƒæ¨¡å¼é€‰æ‹©ï¼š
```bash
./launch_production_training.sh
```
ç„¶åé€‰æ‹©ï¼š
- 1 = å›ºå®šå•æ¨¡æ€è®­ç»ƒï¼ˆç¨³å®šï¼‰
- 2 = è”åˆå¤šæ¨¡æ€è®­ç»ƒï¼ˆæ¨èï¼‰
- 3 = ä¸¤é˜¶æ®µè®­ç»ƒï¼ˆæœ€ä¼˜ï¼‰

### æ–¹æ¡ˆ3ï¼šè‡ªå®šä¹‰å¯åŠ¨
å®Œå…¨æ§åˆ¶è®­ç»ƒå‚æ•°ï¼š

#### å•æ¨¡æ€è®­ç»ƒï¼ˆæ›´ç¨³å®šï¼‰
```bash
nohup python train_fixed_multimodal.py \
    --batch-size 12 \
    --gradient-accumulation 2 \
    --epochs 20 \
    --lr 5e-5 \
    --output-dir /root/autodl-tmp/text2Mol-outputs/my_training \
    > training.log 2>&1 &
```

#### è”åˆå¤šæ¨¡æ€è®­ç»ƒï¼ˆæ›´å¼ºå¤§ï¼‰
```bash
nohup python train_joint_multimodal.py \
    --batch-size 16 \
    --gradient-accumulation 2 \
    --epochs 20 \
    --lr 5e-5 \
    --alignment-weight 0.1 \
    --output-dir /root/autodl-tmp/text2Mol-outputs/joint_training \
    > training.log 2>&1 &
```

## ğŸ“Š ç›‘æ§è®­ç»ƒ

### å®æ—¶ç›‘æ§
```bash
# ä½¿ç”¨Pythonç›‘æ§è„šæœ¬ï¼ˆæ¨èï¼‰
python monitor_training.py

# æŸ¥çœ‹æ‰€æœ‰è®­ç»ƒ
python monitor_training.py --list

# ç›‘æ§æŒ‡å®šç›®å½•
python monitor_training.py --dir /root/autodl-tmp/text2Mol-outputs/production_20250808_120000
```

### æ—¥å¿—æŸ¥çœ‹
```bash
# æŸ¥çœ‹æœ€æ–°æ—¥å¿—
tail -f /root/autodl-tmp/text2Mol-outputs/*/training.log

# æŸ¥çœ‹GPUä½¿ç”¨
watch -n 1 nvidia-smi
```

### TensorBoard
```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir /root/autodl-tmp/text2Mol-outputs/*/tensorboard --port 6006

# ç„¶ååœ¨æµè§ˆå™¨è®¿é—® http://localhost:6006
```

## ğŸ”§ å‚æ•°ä¼˜åŒ–å»ºè®®

### 32GB GPUæœ€ä¼˜é…ç½®
```python
config = {
    'batch_size': 16,               # GPUå†…å­˜å…è®¸çš„æœ€å¤§æ‰¹æ¬¡
    'gradient_accumulation': 2,     # æœ‰æ•ˆæ‰¹æ¬¡ = 16 * 2 = 32
    'learning_rate': 5e-5,          # æ ‡å‡†å­¦ä¹ ç‡
    'warmup_steps': 1000,           # é¢„çƒ­æ­¥æ•°
    'epochs': 20,                   # å®Œæ•´è®­ç»ƒ
    'alignment_weight': 0.1,        # æ¨¡æ€å¯¹é½æƒé‡
    'num_workers': 4,               # æ•°æ®åŠ è½½å¹¶è¡Œ
}
```

### å†…å­˜ä¸è¶³è°ƒæ•´
å¦‚æœé‡åˆ°OOMé”™è¯¯ï¼š
1. å‡å°batch_sizeï¼ˆ12 â†’ 8 â†’ 4ï¼‰
2. å¢åŠ gradient_accumulation
3. å‡å°‘max_text_lengthï¼ˆ128 â†’ 96ï¼‰
4. å‡å°‘max_smiles_lengthï¼ˆ128 â†’ 96ï¼‰

## ğŸ“ è®­ç»ƒæ¨¡å¼è¯¦è§£

### å•æ¨¡æ€è®­ç»ƒ
- **ä¼˜ç‚¹**ï¼šç¨³å®šï¼Œæ”¶æ•›å¿«ï¼Œå†…å­˜å ç”¨å°‘
- **ç¼ºç‚¹**ï¼šä¸èƒ½åˆ©ç”¨å¤šæ¨¡æ€äº’è¡¥ä¿¡æ¯
- **é€‚ç”¨**ï¼šåˆæ¬¡è®­ç»ƒï¼ŒéªŒè¯ç³»ç»Ÿ

### è”åˆå¤šæ¨¡æ€è®­ç»ƒ
- **ä¼˜ç‚¹**ï¼šå……åˆ†åˆ©ç”¨æ‰€æœ‰æ¨¡æ€ï¼Œæ€§èƒ½æœ€ä¼˜
- **ç¼ºç‚¹**ï¼šè®­ç»ƒæ—¶é—´é•¿ï¼Œéœ€è¦æ›´å¤šå†…å­˜
- **é€‚ç”¨**ï¼šç”Ÿäº§ç¯å¢ƒï¼Œè¿½æ±‚æœ€ä½³æ€§èƒ½

### ä¸¤é˜¶æ®µè®­ç»ƒ
- **ç¬¬ä¸€é˜¶æ®µ**ï¼šå•æ¨¡æ€é¢„çƒ­ï¼ˆ5 epochsï¼‰
- **ç¬¬äºŒé˜¶æ®µ**ï¼šå¤šæ¨¡æ€å¾®è°ƒï¼ˆ15 epochsï¼‰
- **ä¼˜ç‚¹**ï¼šç»“åˆä¸¤è€…ä¼˜åŠ¿
- **é€‚ç”¨**ï¼šæ—¶é—´å……è¶³ï¼Œè¿½æ±‚æœ€ä¼˜ç»“æœ

## ğŸ“ˆ é¢„æœŸæ€§èƒ½

### è®­ç»ƒæ—¶é—´ä¼°ç®—ï¼ˆ32GB GPUï¼‰
- å•æ¨¡æ€ï¼š~2å°æ—¶/epochï¼ˆå…¨æ•°æ®é›†ï¼‰
- å¤šæ¨¡æ€ï¼š~3å°æ—¶/epochï¼ˆå…¨æ•°æ®é›†ï¼‰
- å®Œæ•´è®­ç»ƒï¼ˆ20 epochsï¼‰ï¼š40-60å°æ—¶

### é¢„æœŸæŒ‡æ ‡
- Validity: 0.85-0.95
- Uniqueness: 0.80-0.90
- BLEU: 0.70-0.80
- Fingerprint Similarity: 0.75-0.85

## ğŸš¨ å¸¸è§é—®é¢˜

### 1. CUDA Out of Memory
```bash
# è§£å†³æ–¹æ¡ˆ
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
# å‡å°batch_size
```

### 2. è®­ç»ƒä¸­æ–­æ¢å¤
```bash
# ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼ˆåŠŸèƒ½å¼€å‘ä¸­ï¼‰
python train_joint_multimodal.py \
    --resume-from /path/to/checkpoint.pt
```

### 3. æŸ¥çœ‹è®­ç»ƒè¿›ç¨‹
```bash
# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep train

# æŸ¥çœ‹PID
cat /root/autodl-tmp/text2Mol-outputs/*/train.pid
```

### 4. åœæ­¢è®­ç»ƒ
```bash
# ä¼˜é›…åœæ­¢
kill $(cat /root/autodl-tmp/text2Mol-outputs/*/train.pid)

# å¼ºåˆ¶åœæ­¢
kill -9 $(cat /root/autodl-tmp/text2Mol-outputs/*/train.pid)
```

## ğŸ’¾ è¾“å‡ºæ–‡ä»¶è¯´æ˜

è®­ç»ƒä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š
```
output_dir/
â”œâ”€â”€ config.json           # è®­ç»ƒé…ç½®
â”œâ”€â”€ training.log          # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ train.pid            # è¿›ç¨‹ID
â”œâ”€â”€ training_info.json   # è®­ç»ƒä¿¡æ¯
â”œâ”€â”€ training_status.json # å®æ—¶çŠ¶æ€
â”œâ”€â”€ tensorboard/         # TensorBoardæ—¥å¿—
â”œâ”€â”€ checkpoints/         # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ checkpoint-500/
â”‚   â”œâ”€â”€ checkpoint-1000/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ best_model.pt        # æœ€ä½³æ¨¡å‹
â””â”€â”€ final_model.pt       # æœ€ç»ˆæ¨¡å‹
```

## ğŸ¯ ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼š
1. è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼šä½¿ç”¨è¯„ä¼°è„šæœ¬æµ‹è¯•
2. ç”Ÿæˆç¤ºä¾‹ï¼šæµ‹è¯•ä¸åŒæ¨¡æ€è¾“å…¥
3. éƒ¨ç½²åº”ç”¨ï¼šé›†æˆåˆ°ä¸‹æ¸¸ä»»åŠ¡

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶äº†è§£è¯¦ç»†é”™è¯¯
- ä½¿ç”¨ç›‘æ§è„šæœ¬å®æ—¶æŸ¥çœ‹çŠ¶æ€
- æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
- ç¡®ä¿æ•°æ®æ–‡ä»¶è·¯å¾„æ­£ç¡®