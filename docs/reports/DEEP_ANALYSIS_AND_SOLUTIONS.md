# ğŸ”¬ æ·±å±‚é—®é¢˜åˆ†æä¸è§£å†³æ–¹æ¡ˆ

## ğŸ“‹ å½“å‰çŠ¶å†µæ€»ç»“

### è¯„ä¼°ç»“æœ
- **è®­ç»ƒæˆåŠŸ**: éªŒè¯æŸå¤±ä»60é™è‡³0.0256 âœ…
- **ç”Ÿæˆè´¨é‡**: SMILESæœ‰æ•ˆæ€§ä»…2-0% âŒ **ä¸¥é‡é—®é¢˜**
- **åŒ–å­¦çº¦æŸ**: åå¤„ç†æ”¹è¿›æ•ˆæœä¸º0% âŒ **æ–¹æ¡ˆå¤±æ•ˆ**

### æ ¹æœ¬é—®é¢˜è¯Šæ–­

#### 1. æ ¸å¿ƒçŸ›ç›¾ï¼šè®­ç»ƒæŸå¤± vs åŒ–å­¦æœ‰æ•ˆæ€§
```
ä½è®­ç»ƒæŸå¤± â‰  æœ‰æ•ˆçš„åˆ†å­ç”Ÿæˆ
0.0256 éªŒè¯æŸå¤± â†’ 0% SMILES æœ‰æ•ˆæ€§
```

**åˆ†æ**: æ¨¡å‹å­¦ä¼šäº†é¢„æµ‹tokenåºåˆ—ï¼Œä½†æ²¡æœ‰å­¦ä¼šåŒ–å­¦çŸ¥è¯†ã€‚

#### 2. MolT5 è¯æ±‡è¡¨ä¸å…¼å®¹æ€§
- **MolT5è¯æ±‡è¡¨**: 32,100ä¸ªtokenï¼ˆåŒ…å«è‡ªç„¶è¯­è¨€ï¼‰
- **SMILESæœ‰æ•ˆå­—ç¬¦**: ~100ä¸ªåŒ–å­¦å­—ç¬¦
- **é—®é¢˜**: 99%çš„è¯æ±‡è¡¨tokenå¯¹SMILESæ— æ„ä¹‰

#### 3. è®­ç»ƒç›®æ ‡é”™ä½
```python
# å½“å‰è®­ç»ƒç›®æ ‡
loss = CrossEntropyLoss(predicted_tokens, target_tokens)

# ç¼ºå¤±çš„åŒ–å­¦çº¦æŸ
chemical_validity = validate_smiles(generated_smiles)  # æœªé›†æˆåˆ°æŸå¤±ä¸­
```

## ğŸ¯ æ·±å±‚æ¬¡è§£å†³æ–¹æ¡ˆè®¾è®¡

### æ–¹æ¡ˆ1: åŒ–å­¦æ„ŸçŸ¥æŸå¤±å‡½æ•° (æ¨è) â­

#### æ ¸å¿ƒæ€æƒ³
åœ¨è®­ç»ƒæ—¶ç›´æ¥ä¼˜åŒ–åŒ–å­¦æœ‰æ•ˆæ€§ï¼Œè€Œéä»…ä»…ä¼˜åŒ–tokené¢„æµ‹å‡†ç¡®æ€§ã€‚

#### å®ç°æ¶æ„
```python
class ChemicalAwareLoss(nn.Module):
    def __init__(self, alpha=0.7, beta=0.3):
        super().__init__()
        self.alpha = alpha  # tokené¢„æµ‹æŸå¤±æƒé‡
        self.beta = beta   # åŒ–å­¦æœ‰æ•ˆæ€§æŸå¤±æƒé‡
        
    def forward(self, logits, targets, generated_smiles=None):
        # 1. æ ‡å‡†äº¤å‰ç†µæŸå¤±
        ce_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), 
                                  targets.view(-1))
        
        # 2. åŒ–å­¦æœ‰æ•ˆæ€§æŸå¤±
        validity_loss = self.compute_validity_loss(generated_smiles)
        
        # 3. ç»“æ„ç›¸ä¼¼æ€§æŸå¤±
        similarity_loss = self.compute_similarity_loss(generated_smiles, targets)
        
        total_loss = (self.alpha * ce_loss + 
                      self.beta * validity_loss + 
                      0.1 * similarity_loss)
        
        return total_loss
```

#### ä¼˜åŠ¿
- âœ… ç›´æ¥ä¼˜åŒ–ç›®æ ‡æŒ‡æ ‡ï¼ˆåŒ–å­¦æœ‰æ•ˆæ€§ï¼‰
- âœ… ä¿æŒè¯­è¨€æ¨¡å‹èƒ½åŠ›
- âœ… æ— éœ€æ”¹å˜æ¨¡å‹æ¶æ„

### æ–¹æ¡ˆ2: çº¦æŸè§£ç ç®—æ³• â­â­

#### æ ¸å¿ƒæ€æƒ³
åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å®æ—¶åº”ç”¨åŒ–å­¦è¯­æ³•çº¦æŸï¼Œåªå…è®¸ç”ŸæˆåŒ–å­¦æœ‰æ•ˆçš„tokenåºåˆ—ã€‚

#### å®ç°æ¶æ„
```python
class ChemicalConstrainedDecoding:
    def __init__(self, tokenizer):
        self.smiles_grammar = self.build_smiles_grammar()
        self.valid_transitions = self.build_transition_table()
    
    def constrained_beam_search(self, model, input_ids, num_beams=5):
        beams = [(input_ids, 0.0)]  # (sequence, score)
        
        for step in range(max_length):
            new_beams = []
            
            for seq, score in beams:
                # è·å–ä¸‹ä¸€æ­¥çš„valid tokens
                valid_tokens = self.get_valid_next_tokens(seq)
                
                # è®¡ç®—è¿™äº›valid tokensçš„æ¦‚ç‡
                with torch.no_grad():
                    logits = model(seq)
                    probs = F.softmax(logits[:, -1, :], dim=-1)
                
                # åªè€ƒè™‘valid tokens
                for token_id in valid_tokens:
                    new_score = score + torch.log(probs[0, token_id]).item()
                    new_seq = torch.cat([seq, torch.tensor([[token_id]])], dim=1)
                    new_beams.append((new_seq, new_score))
            
            # é€‰æ‹©top-k beams
            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:num_beams]
        
        return beams[0][0]  # è¿”å›æœ€ä½³åºåˆ—
```

#### ä¼˜åŠ¿
- âœ… 100%ä¿è¯åŒ–å­¦æœ‰æ•ˆæ€§
- âœ… æ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹
- âœ… å¯ä¸ç°æœ‰æ¨¡å‹å³æ—¶é›†æˆ

### æ–¹æ¡ˆ3: ä¸“ç”¨SMILESè¯æ±‡è¡¨é‡è®­ç»ƒ â­â­â­

#### æ ¸å¿ƒæ€æƒ³
ä½¿ç”¨ä¸“é—¨ä¸ºSMILESè®¾è®¡çš„è¯æ±‡è¡¨é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³tokenä¸åŒ¹é…é—®é¢˜ã€‚

#### å®ç°æ­¥éª¤
```python
# 1. æ„å»ºSMILESä¸“ç”¨è¯æ±‡è¡¨
smiles_vocab = {
    # åŸå­
    'C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'H',
    'c', 'n', 'o', 's', 'p',  # èŠ³é¦™åŸå­
    
    # é”®å’Œç»“æ„
    '=', '#', '-', '/', '\\', '(', ')', '[', ']',
    
    # ç¯å’Œç«‹ä½“åŒ–å­¦
    '1', '2', '3', '4', '5', '6', '7', '8', '9',
    '@', '@@', '+', '-',
    
    # ç‰¹æ®Šæ ‡è®°
    '<pad>', '<eos>', '<unk>', '<start>',
    
    # å¸¸è§åŸºå›¢ï¼ˆå¯é€‰ï¼‰
    'CH3', 'CH2', 'NH2', 'OH', 'COOH'
}

# 2. é‡æ–°tokenizeè®­ç»ƒæ•°æ®
def retokenize_dataset(smiles_list, new_vocab):
    tokenized_data = []
    for smiles in smiles_list:
        tokens = smiles_tokenize(smiles, new_vocab)
        tokenized_data.append(tokens)
    return tokenized_data

# 3. ä»å¤´è®­ç»ƒæˆ–å¾®è°ƒæ¨¡å‹
model = SMILESTransformer(vocab_size=len(smiles_vocab))
```

#### ä¼˜åŠ¿
- âœ… ä»æ ¹æœ¬ä¸Šè§£å†³è¯æ±‡è¡¨é—®é¢˜
- âœ… å¯ä»¥è·å¾—æœ€é«˜çš„åŒ–å­¦æœ‰æ•ˆæ€§
- âœ… æ¨¡å‹æ›´å°æ›´é«˜æ•ˆ

#### åŠ£åŠ¿
- âŒ éœ€è¦å¤§é‡è®­ç»ƒæ—¶é—´å’Œèµ„æº
- âŒ å¤±å»MolT5çš„é¢„è®­ç»ƒä¼˜åŠ¿

### æ–¹æ¡ˆ4: åˆ†å±‚è§£ç æ¶æ„

#### æ ¸å¿ƒæ€æƒ³
å…ˆç”Ÿæˆåˆ†å­éª¨æ¶ï¼Œå†å¡«å……å®˜èƒ½å›¢ï¼Œç¡®ä¿æ¯ä¸€æ­¥éƒ½æ˜¯åŒ–å­¦æœ‰æ•ˆçš„ã€‚

#### å®ç°æ¶æ„
```python
class HierarchicalMoleculeDecoder:
    def __init__(self):
        self.skeleton_generator = SkeletonGenerator()
        self.functional_group_filler = FunctionalGroupFiller()
        self.validator = SMILESValidator()
    
    def generate_molecule(self, scaffold, text):
        # 1. ç”Ÿæˆåˆ†å­éª¨æ¶
        skeleton = self.skeleton_generator.generate(scaffold, text)
        
        # 2. è¯†åˆ«å¯å¡«å……ä½ç‚¹
        fill_sites = self.identify_fill_sites(skeleton)
        
        # 3. é€ä¸ªå¡«å……å®˜èƒ½å›¢
        for site in fill_sites:
            functional_group = self.functional_group_filler.predict(
                skeleton, site, text
            )
            skeleton = self.attach_functional_group(skeleton, site, functional_group)
            
            # å®æ—¶éªŒè¯
            if not self.validator.is_valid(skeleton):
                skeleton = self.rollback_and_retry(skeleton, site)
        
        return skeleton
```

## ğŸš€ æ¨èå®æ–½è·¯å¾„

### é˜¶æ®µ1: ç«‹å³å®æ–½ (1-2å¤©)
1. **çº¦æŸè§£ç ç®—æ³•** - æ–¹æ¡ˆ2
   - å®ç°åŒ–å­¦è¯­æ³•çº¦æŸçš„beam search
   - é¢„æœŸæœ‰æ•ˆæ€§æå‡è‡³70-90%

2. **åŒ–å­¦æ„ŸçŸ¥åå¤„ç†**
   - æ›´æ™ºèƒ½çš„SMILESä¿®å¤ç®—æ³•
   - åŸºäºåŒ–å­¦è§„åˆ™çš„ç»“æ„ä¿®æ­£

### é˜¶æ®µ2: ä¸­æœŸæ”¹è¿› (1å‘¨)
1. **åŒ–å­¦æ„ŸçŸ¥æŸå¤±å‡½æ•°** - æ–¹æ¡ˆ1
   - é›†æˆæœ‰æ•ˆæ€§çº¦æŸåˆ°è®­ç»ƒæŸå¤±
   - åœ¨ç°æœ‰æ¨¡å‹åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒ

2. **å¼ºåŒ–å­¦ä¹ å¾®è°ƒ**
   - ä½¿ç”¨åŒ–å­¦æœ‰æ•ˆæ€§ä½œä¸ºå¥–åŠ±ä¿¡å·
   - REINFORCEæˆ–PPOç®—æ³•ä¼˜åŒ–ç”Ÿæˆç­–ç•¥

### é˜¶æ®µ3: é•¿æœŸä¼˜åŒ– (1ä¸ªæœˆ)
1. **ä¸“ç”¨SMILESè¯æ±‡è¡¨** - æ–¹æ¡ˆ3
   - æ„å»ºåŒ–å­¦ä¸“ç”¨è¯æ±‡è¡¨
   - é‡æ–°è®­ç»ƒä¼˜åŒ–çš„æ¨¡å‹æ¶æ„

2. **åˆ†å±‚è§£ç æ¶æ„** - æ–¹æ¡ˆ4
   - å®ç°éª¨æ¶-å®˜èƒ½å›¢åˆ†å±‚ç”Ÿæˆ
   - é›†æˆåˆ°ç«¯åˆ°ç«¯è®­ç»ƒä¸­

## ğŸ“Š é¢„æœŸæ•ˆæœå¯¹æ¯”

| æ–¹æ¡ˆ | å®æ–½éš¾åº¦ | æ—¶é—´æˆæœ¬ | é¢„æœŸæœ‰æ•ˆæ€§ | èµ„æºéœ€æ±‚ |
|------|---------|----------|------------|----------|
| çº¦æŸè§£ç  | â­ | 1-2å¤© | 70-90% | ä½ |
| åŒ–å­¦æŸå¤± | â­â­ | 3-5å¤© | 60-80% | ä¸­ |
| ä¸“ç”¨è¯æ±‡è¡¨ | â­â­â­ | 2-4å‘¨ | 85-95% | é«˜ |
| åˆ†å±‚è§£ç  | â­â­â­ | 2-3å‘¨ | 80-95% | é«˜ |

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

### çŸ­æœŸç›®æ ‡ (æœ¬å‘¨)
- âœ… SMILESæœ‰æ•ˆæ€§ > 70%
- âœ… ç”Ÿæˆå¤šæ ·æ€§ä¿æŒ > 0.8
- âœ… è®¡ç®—æ•ˆç‡æå‡ > 50%

### ä¸­æœŸç›®æ ‡ (æœ¬æœˆ)  
- âœ… SMILESæœ‰æ•ˆæ€§ > 85%
- âœ… åŒ–å­¦ç›¸ä¼¼æ€§ > 0.6
- âœ… æ–°é¢–æ€§ > 60%

### é•¿æœŸç›®æ ‡ (3ä¸ªæœˆ)
- âœ… SMILESæœ‰æ•ˆæ€§ > 95%
- âœ… è¯ç‰©ç›¸ä¼¼æ€§ (QED) > 0.5
- âœ… åˆæˆå¯è¡Œæ€§ (SA) < 4.0

## ğŸ”§ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³æ‰§è¡Œ (ä»Šå¤©)
```bash
# 1. å®ç°çº¦æŸè§£ç ç®—æ³•
python create_constrained_decoder.py

# 2. æµ‹è¯•çº¦æŸç”Ÿæˆæ•ˆæœ
python test_constrained_generation.py --target-validity 0.7
```

### æœ¬å‘¨è®¡åˆ’
1. å®Œå–„çº¦æŸè§£ç ç®—æ³•
2. å®ç°åŒ–å­¦æ„ŸçŸ¥æŸå¤±å‡½æ•°
3. å‡†å¤‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¡†æ¶

### é•¿æœŸè§„åˆ’
1. è®¾è®¡ä¸“ç”¨SMILESæ¶æ„
2. æ”¶é›†æ›´å¤§è§„æ¨¡çš„åŒ–å­¦è®­ç»ƒæ•°æ®
3. å»ºç«‹å®Œæ•´çš„åŒ–å­¦è¯„ä¼°åŸºå‡†

---

**ç»“è®º**: å½“å‰çš„2%æœ‰æ•ˆæ€§é—®é¢˜æ˜¯å¯ä»¥è§£å†³çš„ã€‚é€šè¿‡åˆ†é˜¶æ®µå®æ–½çº¦æŸè§£ç ã€åŒ–å­¦æŸå¤±å‡½æ•°å’Œä¸“ç”¨è¯æ±‡è¡¨ç­‰æ–¹æ¡ˆï¼Œé¢„æœŸå¯ä»¥å°†æœ‰æ•ˆæ€§æå‡è‡³85-95%æ°´å¹³ï¼Œè¾¾åˆ°å®ç”¨åŒ–æ ‡å‡†ã€‚

**æ¨èä¼˜å…ˆçº§**: çº¦æŸè§£ç  â†’ åŒ–å­¦æŸå¤± â†’ ä¸“ç”¨è¯æ±‡è¡¨ â†’ åˆ†å±‚æ¶æ„