#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆå¿«é€Ÿå¯åŠ¨è„šæœ¬
"""

import subprocess
import os
import sys
import time
from pathlib import Path

# ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•
os.chdir('/root/text2Mol/scaffold-mol-generation')

# åˆ›å»ºå¿…è¦çš„ç›®å½•
Path("logs").mkdir(exist_ok=True)
Path("/root/autodl-tmp/text2Mol-outputs/fast_training").mkdir(parents=True, exist_ok=True)

def test_training_script():
    """æµ‹è¯•è®­ç»ƒè„šæœ¬æ˜¯å¦å¯ç”¨"""
    if not Path("train_multimodal.py").exists():
        print("âŒ é”™è¯¯: train_multimodal.py ä¸å­˜åœ¨!")
        print("å½“å‰ç›®å½•:", os.getcwd())
        print("ç›®å½•å†…å®¹:", os.listdir("."))
        return False
    
    # æµ‹è¯•å¯¼å…¥
    try:
        result = subprocess.run(
            [sys.executable, "-c", "import sys; sys.path.append('.'); from train_multimodal import *"],
            capture_output=True,
            text=True,
            timeout=5
        )
        if result.returncode != 0:
            print("âš ï¸ è®­ç»ƒè„šæœ¬å¯¼å…¥æµ‹è¯•å¤±è´¥:")
            print(result.stderr[:500])
            return False
    except Exception as e:
        print(f"âš ï¸ æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def start_simple_training(modality, gpu_id):
    """ç®€åŒ–çš„è®­ç»ƒå¯åŠ¨"""
    
    print(f"\nğŸš€ å¯åŠ¨ {modality} è®­ç»ƒ (GPU {gpu_id})")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = f"/root/autodl-tmp/text2Mol-outputs/fast_training/{modality}"
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # ä¼˜åŒ–çš„å‚æ•°
    params = {
        'smiles': {'batch': 32, 'lr': 3e-5},  # å‡å°batch sizeé¿å…OOM
        'graph': {'batch': 16, 'lr': 2e-5}, 
        'image': {'batch': 8, 'lr': 1e-5}
    }
    
    config = params[modality]
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        sys.executable,
        "train_multimodal.py",
        "--scaffold-modality", modality,
        "--output-dir", output_dir,
        "--batch-size", str(config['batch']),
        "--lr", str(config['lr']),
        "--epochs", "1",  # å…ˆè®­ç»ƒ1ä¸ªepochæµ‹è¯•
    ]
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
    env['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
    
    # æ—¥å¿—æ–‡ä»¶
    log_file = f"logs/fast_{modality}_{time.strftime('%H%M%S')}.log"
    print(f"  æ—¥å¿—: {log_file}")
    print(f"  å‘½ä»¤: {' '.join(cmd)}")
    
    try:
        with open(log_file, 'w') as f:
            process = subprocess.Popen(
                cmd,
                stdout=f,
                stderr=subprocess.STDOUT,
                env=env,
                cwd='/root/text2Mol/scaffold-mol-generation'  # æ˜ç¡®æŒ‡å®šå·¥ä½œç›®å½•
            )
            print(f"  âœ… PID: {process.pid}")
            return process
    except Exception as e:
        print(f"  âŒ å¯åŠ¨å¤±è´¥: {e}")
        return None

def monitor_training(processes):
    """ç›‘æ§è®­ç»ƒè¿›åº¦"""
    print("\nğŸ“Š ç›‘æ§è®­ç»ƒè¿›åº¦...")
    print("æŸ¥çœ‹æ—¥å¿—: tail -f logs/fast_*.log")
    print("æŸ¥çœ‹GPU: nvidia-smi -l 1")
    print("\nç­‰å¾…è®­ç»ƒ...\n")
    
    start_time = time.time()
    
    # ç›‘æ§å¾ªç¯
    while any(p and p.poll() is None for p in processes.values()):
        time.sleep(30)
        
        elapsed = time.time() - start_time
        status = f"â±ï¸ è¿è¡Œæ—¶é—´: {elapsed/60:.1f}åˆ†é’Ÿ"
        
        for modality, proc in processes.items():
            if proc:
                if proc.poll() is None:
                    status += f" | {modality}: è¿è¡Œä¸­"
                else:
                    status += f" | {modality}: å®Œæˆ(è¿”å›ç :{proc.returncode})"
        
        print(f"\r{status}", end='', flush=True)
    
    print("\n\nâœ… è®­ç»ƒç»“æŸ!")
    
    # æ£€æŸ¥ç»“æœ
    for modality, proc in processes.items():
        if proc and proc.returncode != 0:
            print(f"âš ï¸ {modality} è®­ç»ƒå¯èƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

def main():
    print("ğŸ”§ ä¿®å¤ç‰ˆå¿«é€Ÿè®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 60)
    
    # æµ‹è¯•ç¯å¢ƒ
    print("\n1. æµ‹è¯•ç¯å¢ƒ...")
    if not test_training_script():
        print("\nè¯·ä¿®å¤è®­ç»ƒè„šæœ¬åé‡è¯•")
        return
    
    print("âœ… ç¯å¢ƒæµ‹è¯•é€šè¿‡")
    
    # æ£€æŸ¥GPU
    print("\n2. æ£€æŸ¥GPU...")
    try:
        result = subprocess.run(['nvidia-smi', '--list-gpus'], capture_output=True, text=True)
        print(result.stdout)
    except:
        print("âš ï¸ æ— æ³•æ£€æŸ¥GPU")
    
    # å¯åŠ¨è®­ç»ƒ
    print("\n3. å¼€å§‹å¯åŠ¨è®­ç»ƒ...")
    
    processes = {}
    
    # å…ˆåªå¯åŠ¨SMILESæµ‹è¯•
    processes['smiles'] = start_simple_training('smiles', 0)
    
    if processes['smiles']:
        print("\nç­‰å¾…10ç§’æ£€æŸ¥æ˜¯å¦æ­£å¸¸è¿è¡Œ...")
        time.sleep(10)
        
        if processes['smiles'].poll() is None:
            print("âœ… SMILESè®­ç»ƒæ­£å¸¸è¿è¡Œ")
            
            # å¯åŠ¨å…¶ä»–æ¨¡æ€
            processes['graph'] = start_simple_training('graph', 1)
            
            # ç›‘æ§æ‰€æœ‰è®­ç»ƒ
            monitor_training(processes)
        else:
            print("âŒ SMILESè®­ç»ƒå¯åŠ¨å¤±è´¥")
            print("æ£€æŸ¥æ—¥å¿—: tail logs/fast_smiles_*.log")
    
    print("\nè®­ç»ƒå¯åŠ¨å™¨ç»“æŸ")

if __name__ == "__main__":
    main()