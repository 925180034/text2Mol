#!/usr/bin/env python3
"""
å®žé™…å¯ç”¨çš„å¿«é€Ÿè®­ç»ƒè„šæœ¬
"""

import os
import sys
import subprocess
import time
from pathlib import Path

# ç¡®ä¿ç›®å½•æ­£ç¡®
os.chdir('/root/text2Mol/scaffold-mol-generation')
Path("logs").mkdir(exist_ok=True)

def launch_training_subprocess(modality, gpu_id):
    """ä½¿ç”¨å­è¿›ç¨‹å¯åŠ¨è®­ç»ƒï¼Œé¿å…å¯¼å…¥è¶…æ—¶é—®é¢˜"""
    
    print(f"\nðŸš€ å¯åŠ¨ {modality} è®­ç»ƒ (GPU {gpu_id})")
    
    # åˆ›å»ºPythonè„šæœ¬å†…å®¹
    script_content = f'''
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '{gpu_id}'

import sys
sys.path.append('/root/text2Mol/scaffold-mol-generation')

print("æ­£åœ¨åŠ è½½æ¨¡å—...")
from train_multimodal import main

# è®¾ç½®å‚æ•°
import argparse
args = argparse.Namespace(
    train_data='Datasets/train.csv',
    val_data='Datasets/validation.csv',
    test_data='Datasets/test.csv',
    output_dir='/root/autodl-tmp/text2Mol-outputs/fast_training/{modality}',
    batch_size={{'smiles': 32, 'graph': 16, 'image': 8}[modality]},
    epochs=1,  # å…ˆè®­ç»ƒ1ä¸ªepoch
    lr={{'smiles': 3e-5, 'graph': 2e-5, 'image': 1e-5}[modality]},
    scaffold_modality='{modality}',
    resume=None,
    device='cuda',
    config=None,
    modality='{modality}'
)

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(args.output_dir, exist_ok=True)

print(f"å¼€å§‹è®­ç»ƒ {modality}...")
try:
    # è°ƒç”¨mainå‡½æ•°
    import sys
    sys.argv = ['train_multimodal.py']  # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
    
    # ç›´æŽ¥è¿è¡Œè®­ç»ƒ
    exec(open('train_multimodal.py').read())
except Exception as e:
    print("è®­ç»ƒå‡ºé”™:", e)
    import traceback
    traceback.print_exc()
'''
    
    # å†™å…¥ä¸´æ—¶è„šæœ¬
    script_path = f"/tmp/train_{modality}_{gpu_id}.py"
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    # å¯åŠ¨è®­ç»ƒ
    log_file = f"logs/train_{modality}_{time.strftime('%H%M%S')}.log"
    
    cmd = [sys.executable, script_path]
    
    print(f"  æ—¥å¿—: {log_file}")
    
    with open(log_file, 'w') as f:
        process = subprocess.Popen(
            cmd,
            stdout=f,
            stderr=subprocess.STDOUT
        )
    
    print(f"  âœ… PID: {process.pid}")
    return process

def simple_direct_train():
    """ç›´æŽ¥è°ƒç”¨è®­ç»ƒï¼Œæœ€ç®€å•çš„æ–¹å¼"""
    
    print("ðŸš€ ç›´æŽ¥è®­ç»ƒæ¨¡å¼")
    print("=" * 60)
    
    # æ£€æŸ¥GPU
    os.system("nvidia-smi --query-gpu=index,name,memory.used,memory.total --format=csv")
    
    print("\nå¼€å§‹è®­ç»ƒ...")
    
    # ä½¿ç”¨æœ€ç®€å•çš„æ–¹å¼ - ç›´æŽ¥å‘½ä»¤è¡Œè°ƒç”¨
    commands = [
        # SMILES on GPU 0
        "CUDA_VISIBLE_DEVICES=0 python train_multimodal.py --scaffold-modality smiles --batch-size 32 --epochs 1 --output-dir /root/autodl-tmp/text2Mol-outputs/fast_training/smiles > logs/smiles.log 2>&1 &",
        
        # Graph on GPU 1
        "CUDA_VISIBLE_DEVICES=1 python train_multimodal.py --scaffold-modality graph --batch-size 16 --epochs 1 --output-dir /root/autodl-tmp/text2Mol-outputs/fast_training/graph > logs/graph.log 2>&1 &"
    ]
    
    for cmd in commands:
        print(f"\næ‰§è¡Œ: {cmd}")
        os.system(cmd)
        time.sleep(5)
    
    print("\nâœ… è®­ç»ƒå·²åœ¨åŽå°å¯åŠ¨!")
    print("\næŸ¥çœ‹è¿›åº¦:")
    print("  tail -f logs/smiles.log")
    print("  tail -f logs/graph.log")
    print("\næŸ¥çœ‹GPU:")
    print("  nvidia-smi -l 1")
    print("\næŸ¥çœ‹è¿›ç¨‹:")
    print("  ps aux | grep train_multimodal")

def main():
    print("é€‰æ‹©å¯åŠ¨æ–¹å¼:")
    print("1. å­è¿›ç¨‹æ–¹å¼ï¼ˆæŽ¨èï¼‰")
    print("2. ç›´æŽ¥å‘½ä»¤è¡Œæ–¹å¼")
    
    choice = input("è¯·é€‰æ‹© (1/2ï¼Œé»˜è®¤1): ").strip() or "1"
    
    if choice == "1":
        # å­è¿›ç¨‹æ–¹å¼
        processes = {}
        processes['smiles'] = launch_training_subprocess('smiles', 0)
        time.sleep(10)
        processes['graph'] = launch_training_subprocess('graph', 1)
        
        print("\nç›‘æŽ§è®­ç»ƒ...")
        while any(p.poll() is None for p in processes.values()):
            time.sleep(30)
            status = "çŠ¶æ€: "
            for name, p in processes.items():
                if p.poll() is None:
                    status += f"{name}:è¿è¡Œä¸­ "
                else:
                    status += f"{name}:å®Œæˆ "
            print(f"\r{status}", end='', flush=True)
            
    else:
        # ç›´æŽ¥å‘½ä»¤è¡Œæ–¹å¼
        simple_direct_train()

if __name__ == "__main__":
    # å¦‚æžœæœ‰å‚æ•°ï¼Œç›´æŽ¥ä½¿ç”¨å‘½ä»¤è¡Œæ–¹å¼
    if len(sys.argv) > 1 and sys.argv[1] == "--direct":
        simple_direct_train()
    else:
        main()