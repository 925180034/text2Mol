#!/usr/bin/env python3
"""
åˆ›å»ºæ”¹è¿›çš„è®­ç»ƒè„šæœ¬ï¼Œè§£å†³ç£ç›˜ç©ºé—´é—®é¢˜
"""

from pathlib import Path

def create_improved_script():
    """åˆ›å»ºæ”¹è¿›çš„safe_background_training.py"""
    
    improved_script = '''#!/usr/bin/env python3
"""
æ”¹è¿›çš„åå°è®­ç»ƒè„šæœ¬ - å¢å¼ºç£ç›˜ç©ºé—´ç®¡ç†
"""

import os
import sys
import subprocess
import time
import signal
import shutil
from pathlib import Path
import psutil
import datetime
import threading

class ImprovedSafeTrainingManager:
    def __init__(self):
        self.base_output_dir = "/root/autodl-tmp/text2Mol-outputs/safe_training"
        self.log_dir = Path("logs")
        self.log_dir.mkdir(exist_ok=True)
        
        # æ”¹è¿›çš„é…ç½®
        self.CHECK_INTERVAL = 60  # ä»5åˆ†é’Ÿæ”¹ä¸º1åˆ†é’Ÿ
        self.MAX_CHECKPOINTS = 3  # æœ€å¤šä¿ç•™3ä¸ªcheckpoint
        self.CHECKPOINT_FREQUENCY = 2000  # æ¯2000æ­¥ä¿å­˜ä¸€æ¬¡(åŸæ¥æ˜¯1000æ­¥)
        self.monitoring = True
        
    def get_disk_info(self):
        """è·å–ç£ç›˜ä½¿ç”¨ä¿¡æ¯"""
        disk_usage = shutil.disk_usage("/root/autodl-tmp")
        return {
            'total_gb': disk_usage.total / (1024**3),
            'used_gb': disk_usage.used / (1024**3),
            'free_gb': disk_usage.free / (1024**3),
            'used_percent': (disk_usage.used / disk_usage.total) * 100
        }
    
    def cleanup_checkpoints_aggressive(self, modality_dir):
        """æ›´æ¿€è¿›çš„checkpointæ¸…ç†ç­–ç•¥"""
        checkpoint_files = []
        
        # æŸ¥æ‰¾æ‰€æœ‰checkpointæ–‡ä»¶
        for file in Path(modality_dir).glob("*.pt"):
            if any(keyword in file.name.lower() for keyword in ['checkpoint', 'model', 'epoch']):
                stat = file.stat()
                checkpoint_files.append({
                    'path': file,
                    'size': stat.st_size,
                    'mtime': stat.st_mtime,
                    'name': file.name
                })
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        checkpoint_files.sort(key=lambda x: x['mtime'], reverse=True)
        
        # ç‰¹æ®Šå¤„ç†ï¼šä¿ç•™best_modelå’Œæœ€æ–°çš„checkpoint
        essential_files = set()
        for ckpt in checkpoint_files:
            if 'best' in ckpt['name'].lower():
                essential_files.add(ckpt['path'])
                break
        
        # ä¿ç•™æœ€æ–°çš„Nä¸ªcheckpoint
        kept_count = 0
        total_freed = 0
        
        for ckpt in checkpoint_files:
            if ckpt['path'] in essential_files:
                continue
                
            if kept_count < self.MAX_CHECKPOINTS:
                kept_count += 1
                print(f"  ä¿ç•™: {ckpt['name']} ({ckpt['size']/(1024**3):.1f}GB)")
            else:
                # åˆ é™¤å¤šä½™çš„æ–‡ä»¶
                try:
                    size_gb = ckpt['size'] / (1024**3)
                    ckpt['path'].unlink()
                    total_freed += size_gb
                    print(f"  åˆ é™¤: {ckpt['name']} ({size_gb:.1f}GB)")
                except Exception as e:
                    print(f"  åˆ é™¤å¤±è´¥: {ckpt['name']} - {e}")
        
        return total_freed
    
    def create_training_config(self, modality):
        """åˆ›å»ºä¼˜åŒ–çš„è®­ç»ƒé…ç½®"""
        config_path = Path(f"configs/safe_{modality}_config.yaml")
        config_path.parent.mkdir(exist_ok=True)
        
        # åŸºç¡€é…ç½®
        base_config = {
            'smiles': {
                'batch_size': 16,
                'learning_rate': 2e-5,
                'save_frequency': 2000,  # å¢åŠ ä¿å­˜é—´éš”
                'max_checkpoints': 3
            },
            'graph': {
                'batch_size': 8,
                'learning_rate': 1e-5,
                'save_frequency': 2000,
                'max_checkpoints': 3
            },
            'image': {
                'batch_size': 6,  # å‡å°batch sizeä»¥å‡å°‘å†…å­˜ä½¿ç”¨
                'learning_rate': 1e-5,
                'save_frequency': 2000,
                'max_checkpoints': 3
            }
        }
        
        config_content = f"""# å®‰å…¨è®­ç»ƒé…ç½® - {modality}æ¨¡æ€
# ç”Ÿæˆæ—¶é—´: {datetime.datetime.now()}

# æ•°æ®é…ç½®
data:
  train_file: 'Datasets/train.csv'
  val_file: 'Datasets/validation.csv'
  test_file: 'Datasets/test.csv'
  modality: '{modality}'
  batch_size: {base_config[modality]['batch_size']}
  num_workers: 4
  
# æ¨¡å‹é…ç½®
model:
  hidden_size: 768
  num_layers: 6
  num_heads: 12
  dropout: 0.1
  fusion_type: 'both'
  use_cached_molt5: true

# è®­ç»ƒé…ç½®
training:
  num_epochs: 5
  learning_rate: {base_config[modality]['learning_rate']}
  warmup_steps: 500
  gradient_accumulation_steps: 2
  max_grad_norm: 1.0
  
  # æ”¹è¿›çš„checkpointé…ç½®
  save_frequency: {base_config[modality]['save_frequency']}
  save_total_limit: {base_config[modality]['max_checkpoints']}
  save_best_only: false  # åŒæ—¶ä¿å­˜bestå’Œcheckpoint
  
  # ç£ç›˜ç©ºé—´ä¿æŠ¤
  disk_space_threshold: 5.0  # GBï¼Œä½äºæ­¤å€¼åœæ­¢è®­ç»ƒ
  auto_cleanup: true
  cleanup_keep_count: 3

# æ—¥å¿—é…ç½®
logging:
  log_every_n_steps: 100
  tensorboard: true
  wandb: false

# æ€§èƒ½ä¼˜åŒ–
optimization:
  fp16: true  # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
  gradient_checkpointing: true  # å‡å°‘æ˜¾å­˜ä½¿ç”¨
  find_unused_parameters: false
"""
        
        config_path.write_text(config_content)
        return str(config_path)
    
    def monitor_disk_space_aggressive(self, training_pid):
        """æ›´æ¿€è¿›çš„ç£ç›˜ç›‘æ§"""
        last_cleanup_time = time.time()
        
        while self.monitoring:
            try:
                if not psutil.pid_exists(training_pid):
                    print("è®­ç»ƒè¿›ç¨‹å·²ç»“æŸ")
                    break
                
                disk_info = self.get_disk_info()
                current_time = time.time()
                
                # æ¯åˆ†é’Ÿè¾“å‡ºä¸€æ¬¡çŠ¶æ€
                print(f"\\n[{datetime.datetime.now().strftime('%H:%M:%S')}] ç£ç›˜ç›‘æ§:")
                print(f"  ä½¿ç”¨ç‡: {disk_info['used_percent']:.1f}%")
                print(f"  å¯ç”¨ç©ºé—´: {disk_info['free_gb']:.1f}GB")
                
                # å¤šçº§å“åº”ç­–ç•¥
                if disk_info['used_percent'] > 95 or disk_info['free_gb'] < 5:
                    print("ğŸš¨ ç´§æ€¥ï¼ç£ç›˜ç©ºé—´ä¸¥é‡ä¸è¶³")
                    self.emergency_cleanup(training_pid)
                elif disk_info['used_percent'] > 90 or disk_info['free_gb'] < 10:
                    print("âš ï¸ ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œç«‹å³æ¸…ç†")
                    self.perform_cleanup()
                elif disk_info['used_percent'] > 80 or disk_info['free_gb'] < 15:
                    # æ¯10åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
                    if current_time - last_cleanup_time > 600:
                        print("ğŸ§¹ å®šæœŸæ¸…ç†")
                        self.perform_cleanup()
                        last_cleanup_time = current_time
                
                time.sleep(self.CHECK_INTERVAL)
                
            except Exception as e:
                print(f"ç›‘æ§é”™è¯¯: {e}")
                time.sleep(30)
    
    def perform_cleanup(self):
        """æ‰§è¡Œæ¸…ç†"""
        print("\\nğŸ§¹ å¼€å§‹æ¸…ç†checkpointæ–‡ä»¶...")
        total_freed = 0
        
        for modality in ['smiles', 'graph', 'image']:
            modality_dir = Path(self.base_output_dir) / modality
            if modality_dir.exists():
                freed = self.cleanup_checkpoints_aggressive(modality_dir)
                total_freed += freed
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œé‡Šæ”¾äº† {total_freed:.1f}GB")
        
        # æ˜¾ç¤ºæ¸…ç†åçŠ¶æ€
        disk_info = self.get_disk_info()
        print(f"æ¸…ç†å: ä½¿ç”¨ç‡ {disk_info['used_percent']:.1f}%, å¯ç”¨ {disk_info['free_gb']:.1f}GB")
    
    def emergency_cleanup(self, training_pid):
        """ç´§æ€¥æ¸…ç†å¹¶å¯èƒ½åœæ­¢è®­ç»ƒ"""
        print("\\nğŸš¨ æ‰§è¡Œç´§æ€¥æ¸…ç†...")
        self.perform_cleanup()
        
        # å†æ¬¡æ£€æŸ¥
        disk_info = self.get_disk_info()
        if disk_info['free_gb'] < 3:
            print("âŒ ç©ºé—´ä»ç„¶ä¸è¶³ï¼Œåœæ­¢è®­ç»ƒï¼")
            try:
                os.kill(training_pid, signal.SIGTERM)
                print("âœ… å·²åœæ­¢è®­ç»ƒè¿›ç¨‹")
            except:
                pass
            self.monitoring = False
    
    def start_training(self, modality):
        """å¯åŠ¨è®­ç»ƒ"""
        print(f"\\nğŸš€ å¯åŠ¨æ”¹è¿›çš„{modality}æ¨¡æ€è®­ç»ƒ")
        print("=" * 60)
        
        # æ£€æŸ¥åˆå§‹ç£ç›˜ç©ºé—´
        disk_info = self.get_disk_info()
        print(f"åˆå§‹ç£ç›˜çŠ¶æ€: {disk_info['used_percent']:.1f}% ä½¿ç”¨, {disk_info['free_gb']:.1f}GB å¯ç”¨")
        
        if disk_info['free_gb'] < 10:
            print("âš ï¸ å¯ç”¨ç©ºé—´ä¸è¶³10GBï¼Œå…ˆæ‰§è¡Œæ¸…ç†...")
            self.perform_cleanup()
        
        # åˆ›å»ºé…ç½®æ–‡ä»¶
        config_path = self.create_training_config(modality)
        
        # å‡†å¤‡è¾“å‡ºç›®å½•
        output_dir = Path(self.base_output_dir) / modality
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å‡†å¤‡æ—¥å¿—æ–‡ä»¶
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = self.log_dir / f"improved_{modality}_{timestamp}.log"
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = [
            sys.executable,
            "train_multimodal.py",
            "--config", config_path,
            "--output_dir", str(output_dir),
            "--modality", modality,
            "--checkpoint_frequency", str(self.CHECKPOINT_FREQUENCY),
            "--max_checkpoints", str(self.MAX_CHECKPOINTS)
        ]
        
        print(f"\\næ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
        print(f"é…ç½®æ–‡ä»¶: {config_path}")
        
        # å¯åŠ¨è®­ç»ƒè¿›ç¨‹
        with open(log_file, 'w') as f:
            process = subprocess.Popen(
                cmd,
                stdout=f,
                stderr=subprocess.STDOUT,
                preexec_fn=os.setsid
            )
        
        print(f"\\nâœ… è®­ç»ƒå·²å¯åŠ¨ (PID: {process.pid})")
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(
            target=self.monitor_disk_space_aggressive,
            args=(process.pid,)
        )
        monitor_thread.daemon = True
        monitor_thread.start()
        
        print("âœ… ç£ç›˜ç›‘æ§å·²å¯åŠ¨ (æ£€æŸ¥é—´éš”: 1åˆ†é’Ÿ)")
        print("\\nğŸ’¡ æ”¹è¿›å†…å®¹:")
        print("  - æ£€æŸ¥é—´éš”: 5åˆ†é’Ÿ â†’ 1åˆ†é’Ÿ")
        print("  - ä¿å­˜é¢‘ç‡: æ¯1000æ­¥ â†’ æ¯2000æ­¥")
        print("  - æœ€å¤§æ–‡ä»¶æ•°: æ— é™åˆ¶ â†’ 3ä¸ª")
        print("  - æ¸…ç†ç­–ç•¥: è¢«åŠ¨ â†’ ä¸»åŠ¨")
        print("  - Batch size: 8 â†’ 6 (Imageæ¨¡æ€)")
        
        return process.pid, log_file

def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python improved_safe_training.py [smiles|graph|image]")
        sys.exit(1)
    
    modality = sys.argv[1].lower()
    if modality not in ['smiles', 'graph', 'image']:
        print(f"é”™è¯¯: ä¸æ”¯æŒçš„æ¨¡æ€ '{modality}'")
        print("æ”¯æŒçš„æ¨¡æ€: smiles, graph, image")
        sys.exit(1)
    
    manager = ImprovedSafeTrainingManager()
    pid, log_file = manager.start_training(modality)
    
    print(f"\\nè®­ç»ƒè¿›ç¨‹PID: {pid}")
    print(f"æŸ¥çœ‹æ—¥å¿—: tail -f {log_file}")
    print(f"\\nåœæ­¢è®­ç»ƒ: kill -TERM -{pid}")

if __name__ == "__main__":
    main()
'''
    
    # ä¿å­˜æ”¹è¿›çš„è„šæœ¬
    script_path = Path("improved_safe_training.py")
    script_path.write_text(improved_script)
    script_path.chmod(0o755)
    
    print("âœ… åˆ›å»ºäº†æ”¹è¿›çš„è®­ç»ƒè„šæœ¬: improved_safe_training.py")
    print("\næ”¹è¿›å†…å®¹:")
    print("1. ç›‘æ§é—´éš”: 5åˆ†é’Ÿ â†’ 1åˆ†é’Ÿ")
    print("2. ä¿å­˜é¢‘ç‡: æ¯1000æ­¥ â†’ æ¯2000æ­¥")  
    print("3. æœ€å¤§ä¿ç•™: æ— é™åˆ¶ â†’ 3ä¸ªcheckpoint")
    print("4. æ¸…ç†ç­–ç•¥: è¢«åŠ¨å“åº” â†’ ä¸»åŠ¨æ¸…ç†")
    print("5. ç´§æ€¥å“åº”: å¯ç”¨<3GBæ—¶è‡ªåŠ¨åœæ­¢")
    print("6. Batch sizeä¼˜åŒ–: å‡å°‘å†…å­˜å‹åŠ›")
    
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("1. å…ˆæ¸…ç†ç£ç›˜: python disk_cleanup_report.py --cleanup")
    print("2. å¯åŠ¨æ”¹è¿›è®­ç»ƒ: python improved_safe_training.py image")

if __name__ == "__main__":
    create_improved_script()